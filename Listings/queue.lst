C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 1   


C251 COMPILER V5.60.0, COMPILATION OF MODULE queue
OBJECT MODULE PLACED IN .\Objects\queue.obj
COMPILER INVOKED BY: D:\SDK\Keil_V5\C251\BIN\C251.EXE Sources\FreeRTOS\queue.c XSMALL OA FUNCTIONS(REENTRANT) ROM(HUGE) 
                    -INCDIR(.\Sources\User;.\Sources\User\include;.\Sources\FreeRTOS\include;.\Sources\FreeRTOS\portable\STC32G12K128;.\Sourc
                    -es\TinyMaix) PRINT(.\Listings\queue.lst) TABS(2) OBJECT(.\Objects\queue.obj) 

stmt  level    source

    1          /*
    2           * FreeRTOS Kernel V10.4.6
    3           * Copyright (C) 2021 Amazon.com, Inc. or its affiliates.  All Rights Reserved.
    4           *
    5           * SPDX-License-Identifier: MIT
    6           *
    7           * Permission is hereby granted, free of charge, to any person obtaining a copy of
    8           * this software and associated documentation files (the "Software"), to deal in
    9           * the Software without restriction, including without limitation the rights to
   10           * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
   11           * the Software, and to permit persons to whom the Software is furnished to do so,
   12           * subject to the following conditions:
   13           *
   14           * The above copyright notice and this permission notice shall be included in all
   15           * copies or substantial portions of the Software.
   16           *
   17           * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
   18           * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
   19           * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
   20           * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
   21           * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
   22           * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
   23           *
   24           * https://www.FreeRTOS.org
   25           * https://github.com/FreeRTOS
   26           *
   27           */
   28          
   29          #include <stdlib.h>
   30          #include <string.h>
   31          
   32          /* Defining MPU_WRAPPERS_INCLUDED_FROM_API_FILE prevents task.h from redefining
   33           * all the API functions to use the MPU wrappers.  That should only be done when
   34           * task.h is included from an application file. */
   35          #define MPU_WRAPPERS_INCLUDED_FROM_API_FILE
   36          
   37          #include "FreeRTOS.h"
   38          #include "task.h"
   39          #include "queue.h"
   40          
   41          #if ( configUSE_CO_ROUTINES == 1 )
                   #include "croutine.h"
               #endif
   44          
   45          /* Lint e9021, e961 and e750 are suppressed as a MISRA exception justified
   46           * because the MPU ports require MPU_WRAPPERS_INCLUDED_FROM_API_FILE to be defined
   47           * for the header files above, but not in this file, in order to generate the
   48           * correct privileged Vs unprivileged linkage and placement. */
   49          #undef MPU_WRAPPERS_INCLUDED_FROM_API_FILE /*lint !e961 !e750 !e9021. */
   50          
   51          
   52          /* Constants used with the cRxLock and cTxLock structure members. */
   53          #define queueUNLOCKED             ( ( int8_t ) -1 )
   54          #define queueLOCKED_UNMODIFIED    ( ( int8_t ) 0 )
   55          #define queueINT8_MAX             ( ( int8_t ) 127 )
   56          
   57          /* When the Queue_t structure is used to represent a base queue its pcHead and
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 2   

   58           * pcTail members are used as pointers into the queue storage area.  When the
   59           * Queue_t structure is used to represent a mutex pcHead and pcTail pointers are
   60           * not necessary, and the pcHead pointer is set to NULL to indicate that the
   61           * structure instead holds a pointer to the mutex holder (if any).  Map alternative
   62           * names to the pcHead and structure member to ensure the readability of the code
   63           * is maintained.  The QueuePointers_t and SemaphoreData_t types are used to form
   64           * a union as their usage is mutually exclusive dependent on what the queue is
   65           * being used for. */
   66          #define uxQueueType               pcHead
   67          #define queueQUEUE_IS_MUTEX       NULL
   68          
   69          typedef struct QueuePointers
   70          {
   71              int8_t * pcTail;     /*< Points to the byte at the end of the queue storage area.  Once more byte is 
             -allocated than necessary to store the queue items, this is used as a marker. */
   72              int8_t * pcReadFrom; /*< Points to the last place that a queued item was read from when the structure
             - is used as a queue. */
   73          } QueuePointers_t;
   74          
   75          typedef struct SemaphoreData
   76          {
   77              TaskHandle_t xMutexHolder;        /*< The handle of the task that holds the mutex. */
   78              UBaseType_t uxRecursiveCallCount; /*< Maintains a count of the number of times a recursive mutex has 
             -been recursively 'taken' when the structure is used as a mutex. */
   79          } SemaphoreData_t;
   80          
   81          /* Semaphores do not actually store or copy data, so have an item size of
   82           * zero. */
   83          #define queueSEMAPHORE_QUEUE_ITEM_LENGTH    ( ( UBaseType_t ) 0 )
   84          #define queueMUTEX_GIVE_BLOCK_TIME          ( ( TickType_t ) 0U )
   85          
   86          #if ( configUSE_PREEMPTION == 0 )
               
               /* If the cooperative scheduler is being used then a yield should not be
                * performed just because a higher priority task has been woken. */
                   #define queueYIELD_IF_USING_PREEMPTION()
               #else
   92              #define queueYIELD_IF_USING_PREEMPTION()    portYIELD_WITHIN_API()
   93          #endif
   94          
   95          /*
   96           * Definition of the queue used by the scheduler.
   97           * Items are queued by copy, not reference.  See the following link for the
   98           * rationale: https://www.FreeRTOS.org/Embedded-RTOS-Queues.html
   99           */
  100          typedef struct QueueDefinition /* The old naming convention is used to prevent breaking kernel aware debu
             -ggers. */
  101          {
  102              int8_t * pcHead;           /*< Points to the beginning of the queue storage area. */
  103              int8_t * pcWriteTo;        /*< Points to the free next place in the storage area. */
  104          
  105              union
  106              {
  107                  QueuePointers_t xQueue;     /*< Data required exclusively when this structure is used as a queue.
             - */
  108                  SemaphoreData_t xSemaphore; /*< Data required exclusively when this structure is used as a semaph
             -ore. */
  109              } u;
  110          
  111              List_t xTasksWaitingToSend;             /*< List of tasks that are blocked waiting to post onto this 
             -queue.  Stored in priority order. */
  112              List_t xTasksWaitingToReceive;          /*< List of tasks that are blocked waiting to read from this 
             -queue.  Stored in priority order. */
  113          
  114              volatile UBaseType_t uxMessagesWaiting; /*< The number of items currently in the queue. */
  115              UBaseType_t uxLength;                   /*< The length of the queue defined as the number of items it
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 3   

             - will hold, not the number of bytes. */
  116              UBaseType_t uxItemSize;                 /*< The size of each items that the queue will hold. */
  117          
  118              volatile int8_t cRxLock;                /*< Stores the number of items received from the queue (remov
             -ed from the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */
  119              volatile int8_t cTxLock;                /*< Stores the number of items transmitted to the queue (adde
             -d to the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */
  120          
  121              #if ( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
                       uint8_t ucStaticallyAllocated; /*< Set to pdTRUE if the memory used by the queue was statically a
             -llocated to ensure no attempt is made to free the memory. */
                   #endif
  124          
  125              #if ( configUSE_QUEUE_SETS == 1 )
                       struct QueueDefinition * pxQueueSetContainer;
                   #endif
  128          
  129              #if ( configUSE_TRACE_FACILITY == 1 )
                       UBaseType_t uxQueueNumber;
                       uint8_t ucQueueType;
                   #endif
  133          } xQUEUE;
  134          
  135          /* The old xQUEUE name is maintained above then typedefed to the new Queue_t
  136           * name below to enable the use of older kernel aware debuggers. */
  137          typedef xQUEUE Queue_t;
  138          
  139          /*-----------------------------------------------------------*/
  140          
  141          /*
  142           * The queue registry is just a means for kernel aware debuggers to locate
  143           * queue structures.  It has no other purpose so is an optional component.
  144           */
  145          #if ( configQUEUE_REGISTRY_SIZE > 0 )
               
               /* The type stored within the queue registry array.  This allows a name
                * to be assigned to each queue making kernel aware debugging a little
                * more user friendly. */
                   typedef struct QUEUE_REGISTRY_ITEM
                   {
                       const char * pcQueueName; /*lint !e971 Unqualified char types are allowed for strings and single 
             -characters only. */
                       QueueHandle_t xHandle;
                   } xQueueRegistryItem;
               
               /* The old xQueueRegistryItem name is maintained above then typedefed to the
                * new xQueueRegistryItem name below to enable the use of older kernel aware
                * debuggers. */
                   typedef xQueueRegistryItem QueueRegistryItem_t;
               
               /* The queue registry is simply an array of QueueRegistryItem_t structures.
                * The pcQueueName member of a structure being NULL is indicative of the
                * array position being vacant. */
                   PRIVILEGED_DATA QueueRegistryItem_t xQueueRegistry[ configQUEUE_REGISTRY_SIZE ];
               
               #endif /* configQUEUE_REGISTRY_SIZE */
  167          
  168          /*
  169           * Unlocks a queue locked by a call to prvLockQueue.  Locking a queue does not
  170           * prevent an ISR from adding or removing items to the queue, but does prevent
  171           * an ISR from removing tasks from the queue event lists.  If an ISR finds a
  172           * queue is locked it will instead increment the appropriate queue lock count
  173           * to indicate that a task may require unblocking.  When the queue in unlocked
  174           * these lock counts are inspected, and the appropriate action taken.
  175           */
  176          static void prvUnlockQueue( Queue_t * const pxQueue ) PRIVILEGED_FUNCTION;
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 4   

  177          
  178          /*
  179           * Uses a critical section to determine if there is any data in a queue.
  180           *
  181           * @return pdTRUE if the queue contains no items, otherwise pdFALSE.
  182           */
  183          static BaseType_t prvIsQueueEmpty( const Queue_t * pxQueue ) PRIVILEGED_FUNCTION;
  184          
  185          /*
  186           * Uses a critical section to determine if there is any space in a queue.
  187           *
  188           * @return pdTRUE if there is no space, otherwise pdFALSE;
  189           */
  190          static BaseType_t prvIsQueueFull( const Queue_t * pxQueue ) PRIVILEGED_FUNCTION;
  191          
  192          /*
  193           * Copies an item into the queue, either at the front of the queue or the
  194           * back of the queue.
  195           */
  196          static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue,
  197                                                const void * pvItemToQueue,
  198                                                const BaseType_t xPosition ) PRIVILEGED_FUNCTION;
  199          
  200          /*
  201           * Copies an item out of a queue.
  202           */
  203          static void prvCopyDataFromQueue( Queue_t * const pxQueue,
  204                                            void * const pvBuffer ) PRIVILEGED_FUNCTION;
  205          
  206          #if ( configUSE_QUEUE_SETS == 1 )
               
               /*
                * Checks to see if a queue is a member of a queue set, and if so, notifies
                * the queue set that the queue contains data.
                */
                   static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue ) PRIVILEGED_FUNCTION;
               #endif
  214          
  215          /*
  216           * Called after a Queue_t structure has been allocated either statically or
  217           * dynamically to fill in the structure's members.
  218           */
  219          static void prvInitialiseNewQueue( const UBaseType_t uxQueueLength,
  220                                             const UBaseType_t uxItemSize,
  221                                             uint8_t * pucQueueStorage,
  222                                             const uint8_t ucQueueType,
  223                                             Queue_t * pxNewQueue ) PRIVILEGED_FUNCTION;
  224          
  225          /*
  226           * Mutexes are a special type of queue.  When a mutex is created, first the
  227           * queue is created, then prvInitialiseMutex() is called to configure the queue
  228           * as a mutex.
  229           */
  230          #if ( configUSE_MUTEXES == 1 )
  231              static void prvInitialiseMutex( Queue_t * pxNewQueue ) PRIVILEGED_FUNCTION;
  232          #endif
  233          
  234          #if ( configUSE_MUTEXES == 1 )
  235          
  236          /*
  237           * If a task waiting for a mutex causes the mutex holder to inherit a
  238           * priority, but the waiting task times out, then the holder should
  239           * disinherit the priority - but only down to the highest priority of any
  240           * other tasks that are waiting for the same mutex.  This function returns
  241           * that priority.
  242           */
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 5   

  243              static UBaseType_t prvGetDisinheritPriorityAfterTimeout( const Queue_t * const pxQueue ) PRIVILEGED_F
             -UNCTION;
  244          #endif
  245          /*-----------------------------------------------------------*/
  246          
  247          /*
  248           * Macro to mark a queue as locked.  Locking a queue prevents an ISR from
  249           * accessing the queue event lists.
  250           */
  251          #define prvLockQueue( pxQueue )                            \
  252              taskENTER_CRITICAL();                                  \
  253              {                                                      \
  254                  if( ( pxQueue )->cRxLock == queueUNLOCKED )        \
  255                  {                                                  \
  256                      ( pxQueue )->cRxLock = queueLOCKED_UNMODIFIED; \
  257                  }                                                  \
  258                  if( ( pxQueue )->cTxLock == queueUNLOCKED )        \
  259                  {                                                  \
  260                      ( pxQueue )->cTxLock = queueLOCKED_UNMODIFIED; \
  261                  }                                                  \
  262              }                                                      \
  263              taskEXIT_CRITICAL()
  264          /*-----------------------------------------------------------*/
  265          
  266          BaseType_t xQueueGenericReset( QueueHandle_t xQueue,
  267                                         BaseType_t xNewQueue )
  268          {
  269   1          BaseType_t xReturn = pdPASS;
  270   1          Queue_t * const pxQueue = xQueue;
  271   1      
  272   1          configASSERT( pxQueue );
  273   1      
  274   1          if( ( pxQueue != NULL ) &&
  275   1              ( pxQueue->uxLength >= 1U ) &&
  276   1              /* Check for multiplication overflow. */
  277   1              ( ( SIZE_MAX / pxQueue->uxLength ) >= pxQueue->uxItemSize ) )
  278   1          {
  279   2              taskENTER_CRITICAL();
  280   2              {
  281   3                  pxQueue->u.xQueue.pcTail = pxQueue->pcHead + ( pxQueue->uxLength * pxQueue->uxItemSize ); /*l
             -int !e9016 Pointer arithmetic allowed on char types, especially when it assists conveying intent. */
  282   3                  pxQueue->uxMessagesWaiting = ( UBaseType_t ) 0U;
  283   3                  pxQueue->pcWriteTo = pxQueue->pcHead;
  284   3                  pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead + ( ( pxQueue->uxLength - 1U ) * pxQueue->uxIt
             -emSize ); /*lint !e9016 Pointer arithmetic allowed on char types, especially when it assists conveying intent. */
  285   3                  pxQueue->cRxLock = queueUNLOCKED;
  286   3                  pxQueue->cTxLock = queueUNLOCKED;
  287   3      
  288   3                  if( xNewQueue == pdFALSE )
  289   3                  {
  290   4                      /* If there are tasks blocked waiting to read from the queue, then
  291   4                       * the tasks will remain blocked as after this function exits the queue
  292   4                       * will still be empty.  If there are tasks blocked waiting to write to
  293   4                       * the queue, then one should be unblocked as after this function exits
  294   4                       * it will be possible to write to it. */
  295   4                      if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
  296   4                      {
  297   5                          if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
  298   5                          {
  299   6                              queueYIELD_IF_USING_PREEMPTION();
  300   6                          }
  301   5                          else
  302   5                          {
  303   6                              mtCOVERAGE_TEST_MARKER();
  304   6                          }
  305   5                      }
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 6   

  306   4                      else
  307   4                      {
  308   5                          mtCOVERAGE_TEST_MARKER();
  309   5                      }
  310   4                  }
  311   3                  else
  312   3                  {
  313   4                      /* Ensure the event queues start in the correct state. */
  314   4                      vListInitialise( &( pxQueue->xTasksWaitingToSend ) );
  315   4                      vListInitialise( &( pxQueue->xTasksWaitingToReceive ) );
  316   4                  }
  317   3              }
  318   2              taskEXIT_CRITICAL();
  319   2          }
  320   1          else
  321   1          {
  322   2              xReturn = pdFAIL;
  323   2          }
  324   1      
  325   1          configASSERT( xReturn != pdFAIL );
  326   1      
  327   1          /* A value is returned for calling semantic consistency with previous
  328   1           * versions. */
  329   1          return xReturn;
  330   1      }
  331          /*-----------------------------------------------------------*/
  332          
  333          #if ( configSUPPORT_STATIC_ALLOCATION == 1 )
               
                   QueueHandle_t xQueueGenericCreateStatic( const UBaseType_t uxQueueLength,
                                                            const UBaseType_t uxItemSize,
                                                            uint8_t * pucQueueStorage,
                                                            StaticQueue_t * pxStaticQueue,
                                                            const uint8_t ucQueueType )
                   {
                       Queue_t * pxNewQueue = NULL;
               
                       /* The StaticQueue_t structure and the queue storage area must be
                        * supplied. */
                       configASSERT( pxStaticQueue );
               
                       if( ( uxQueueLength > ( UBaseType_t ) 0 ) &&
                           ( pxStaticQueue != NULL ) &&
               
                           /* A queue storage area should be provided if the item size is not 0, and
                            * should not be provided if the item size is 0. */
                           ( !( ( pucQueueStorage != NULL ) && ( uxItemSize == 0 ) ) ) &&
                           ( !( ( pucQueueStorage == NULL ) && ( uxItemSize != 0 ) ) ) )
                       {
                           #if ( configASSERT_DEFINED == 1 )
                               {
                                   /* Sanity check that the size of the structure used to declare a
                                    * variable of type StaticQueue_t or StaticSemaphore_t equals the size of
                                    * the real queue and semaphore structures. */
                                   volatile size_t xSize = sizeof( StaticQueue_t );
               
                                   /* This assertion cannot be branch covered in unit tests */
                                   configASSERT( xSize == sizeof( Queue_t ) ); /* LCOV_EXCL_BR_LINE */
                                   ( void ) xSize;                             /* Keeps lint quiet when configASSERT() i
             -s not defined. */
                               }
                           #endif /* configASSERT_DEFINED */
               
                           /* The address of a statically allocated queue was passed in, use it.
                            * The address of a statically allocated storage area was also passed in
                            * but is already set. */
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 7   

                           pxNewQueue = ( Queue_t * ) pxStaticQueue; /*lint !e740 !e9087 Unusual cast is ok as the struc
             -tures are designed to have the same alignment, and the size is checked by an assert. */
               
                           #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
                               {
                                   /* Queues can be allocated wither statically or dynamically, so
                                    * note this queue was allocated statically in case the queue is
                                    * later deleted. */
                                   pxNewQueue->ucStaticallyAllocated = pdTRUE;
                               }
                           #endif /* configSUPPORT_DYNAMIC_ALLOCATION */
               
                           prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );
                       }
                       else
                       {
                           configASSERT( pxNewQueue );
                           mtCOVERAGE_TEST_MARKER();
                       }
               
                       return pxNewQueue;
                   }
               
               #endif /* configSUPPORT_STATIC_ALLOCATION */
  394          /*-----------------------------------------------------------*/
  395          
  396          #if ( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
  397          
  398              QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength,
  399                                                 const UBaseType_t uxItemSize,
  400                                                 const uint8_t ucQueueType )
  401              {
  402   1              Queue_t * pxNewQueue = NULL;
  403   1              size_t xQueueSizeInBytes;
  404   1              uint8_t * pucQueueStorage;
  405   1      
  406   1              if( ( uxQueueLength > ( UBaseType_t ) 0 ) &&
  407   1                  /* Check for multiplication overflow. */
  408   1                  ( ( SIZE_MAX / uxQueueLength ) >= uxItemSize ) &&
  409   1                  /* Check for addition overflow. */
  410   1                  ( ( SIZE_MAX - sizeof( Queue_t ) ) >= ( uxQueueLength * uxItemSize ) ) )
  411   1              {
  412   2                  /* Allocate enough space to hold the maximum number of items that
  413   2                   * can be in the queue at any time.  It is valid for uxItemSize to be
  414   2                   * zero in the case the queue is used as a semaphore. */
  415   2                  xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); /*lint !e961 MISRA exception a
             -s the casts are only redundant for some ports. */
  416   2      
  417   2                  /* Allocate the queue and storage area.  Justification for MISRA
  418   2                   * deviation as follows:  pvPortMalloc() always ensures returned memory
  419   2                   * blocks are aligned per the requirements of the MCU stack.  In this case
  420   2                   * pvPortMalloc() must return a pointer that is guaranteed to meet the
  421   2                   * alignment requirements of the Queue_t structure - which in this case
  422   2                   * is an int8_t *.  Therefore, whenever the stack alignment requirements
  423   2                   * are greater than or equal to the pointer to char requirements the cast
  424   2                   * is safe.  In other cases alignment requirements are not strict (one or
  425   2                   * two bytes). */
  426   2                  pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes ); /*lint !e90
             -87 !e9079 see comment above. */
  427   2      
  428   2                  if( pxNewQueue != NULL )
  429   2                  {
  430   3                      /* Jump past the queue structure to find the location of the queue
  431   3                       * storage area. */
  432   3                      pucQueueStorage = ( uint8_t * ) pxNewQueue;
  433   3                      pucQueueStorage += sizeof( Queue_t ); /*lint !e9016 Pointer arithmetic allowed on char ty
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 8   

             -pes, especially when it assists conveying intent. */
  434   3      
  435   3                      #if ( configSUPPORT_STATIC_ALLOCATION == 1 )
                                   {
                                       /* Queues can be created either statically or dynamically, so
                                        * note this task was created dynamically in case it is later
                                        * deleted. */
                                       pxNewQueue->ucStaticallyAllocated = pdFALSE;
                                   }
                               #endif /* configSUPPORT_STATIC_ALLOCATION */
  443   3      
  444   3                      prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueu
             -e );
  445   3                  }
  446   2                  else
  447   2                  {
  448   3                      traceQUEUE_CREATE_FAILED( ucQueueType );
  449   3                      mtCOVERAGE_TEST_MARKER();
  450   3                  }
  451   2              }
  452   1              else
  453   1              {
  454   2                  configASSERT( pxNewQueue );
  455   2                  mtCOVERAGE_TEST_MARKER();
  456   2              }
  457   1      
  458   1              return pxNewQueue;
  459   1          }
  460          
  461          #endif /* configSUPPORT_STATIC_ALLOCATION */
  462          /*-----------------------------------------------------------*/
  463          
  464          static void prvInitialiseNewQueue( const UBaseType_t uxQueueLength,
  465                                             const UBaseType_t uxItemSize,
  466                                             uint8_t * pucQueueStorage,
  467                                             const uint8_t ucQueueType,
  468                                             Queue_t * pxNewQueue )
  469          {
  470   1          /* Remove compiler warnings about unused parameters should
  471   1           * configUSE_TRACE_FACILITY not be set to 1. */
  472   1          UNUSED( ucQueueType );
  473   1      
  474   1          if( uxItemSize == ( UBaseType_t ) 0 )
  475   1          {
  476   2              /* No RAM was allocated for the queue storage area, but PC head cannot
  477   2               * be set to NULL because NULL is used as a key to say the queue is used as
  478   2               * a mutex.  Therefore just set pcHead to point to the queue as a benign
  479   2               * value that is known to be within the memory map. */
  480   2              pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
  481   2          }
  482   1          else
  483   1          {
  484   2              /* Set the head to the start of the queue storage area. */
  485   2              pxNewQueue->pcHead = ( int8_t * ) pucQueueStorage;
  486   2          }
  487   1      
  488   1          /* Initialise the queue members as described where the queue type is
  489   1           * defined. */
  490   1          pxNewQueue->uxLength = uxQueueLength;
  491   1          pxNewQueue->uxItemSize = uxItemSize;
  492   1          ( void ) xQueueGenericReset( pxNewQueue, pdTRUE );
  493   1      
  494   1          #if ( configUSE_TRACE_FACILITY == 1 )
                       {
                           pxNewQueue->ucQueueType = ucQueueType;
                       }
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 9   

                   #endif /* configUSE_TRACE_FACILITY */
  499   1      
  500   1          #if ( configUSE_QUEUE_SETS == 1 )
                       {
                           pxNewQueue->pxQueueSetContainer = NULL;
                       }
                   #endif /* configUSE_QUEUE_SETS */
  505   1      
  506   1          traceQUEUE_CREATE( pxNewQueue );
  507   1      }
  508          /*-----------------------------------------------------------*/
  509          
  510          #if ( configUSE_MUTEXES == 1 )
  511          
  512              static void prvInitialiseMutex( Queue_t * pxNewQueue )
  513              {
  514   1              if( pxNewQueue != NULL )
  515   1              {
  516   2                  /* The queue create function will set all the queue structure members
  517   2                  * correctly for a generic queue, but this function is creating a
  518   2                  * mutex.  Overwrite those members that need to be set differently -
  519   2                  * in particular the information required for priority inheritance. */
  520   2                  pxNewQueue->u.xSemaphore.xMutexHolder = NULL;
  521   2                  pxNewQueue->uxQueueType = queueQUEUE_IS_MUTEX;
  522   2      
  523   2                  /* In case this is a recursive mutex. */
  524   2                  pxNewQueue->u.xSemaphore.uxRecursiveCallCount = 0;
  525   2      
  526   2                  traceCREATE_MUTEX( pxNewQueue );
  527   2      
  528   2                  /* Start with the semaphore in the expected state. */
  529   2                  ( void ) xQueueGenericSend( pxNewQueue, NULL, ( TickType_t ) 0U, queueSEND_TO_BACK );
  530   2              }
  531   1              else
  532   1              {
  533   2                  traceCREATE_MUTEX_FAILED();
  534   2              }
  535   1          }
  536          
  537          #endif /* configUSE_MUTEXES */
  538          /*-----------------------------------------------------------*/
  539          
  540          #if ( ( configUSE_MUTEXES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
  541          
  542              QueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType )
  543              {
  544   1              QueueHandle_t xNewQueue;
  545   1              const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;
  546   1      
  547   1              xNewQueue = xQueueGenericCreate( uxMutexLength, uxMutexSize, ucQueueType );
  548   1              prvInitialiseMutex( ( Queue_t * ) xNewQueue );
  549   1      
  550   1              return xNewQueue;
  551   1          }
  552          
  553          #endif /* configUSE_MUTEXES */
  554          /*-----------------------------------------------------------*/
  555          
  556          #if ( ( configUSE_MUTEXES == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
               
                   QueueHandle_t xQueueCreateMutexStatic( const uint8_t ucQueueType,
                                                          StaticQueue_t * pxStaticQueue )
                   {
                       QueueHandle_t xNewQueue;
                       const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;
               
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 10  

                       /* Prevent compiler warnings about unused parameters if
                        * configUSE_TRACE_FACILITY does not equal 1. */
                       ( void ) ucQueueType;
               
                       xNewQueue = xQueueGenericCreateStatic( uxMutexLength, uxMutexSize, NULL, pxStaticQueue, ucQueueTy
             -pe );
                       prvInitialiseMutex( ( Queue_t * ) xNewQueue );
               
                       return xNewQueue;
                   }
               
               #endif /* configUSE_MUTEXES */
  575          /*-----------------------------------------------------------*/
  576          
  577          #if ( ( configUSE_MUTEXES == 1 ) && ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) )
               
                   TaskHandle_t xQueueGetMutexHolder( QueueHandle_t xSemaphore )
                   {
                       TaskHandle_t pxReturn;
                       Queue_t * const pxSemaphore = ( Queue_t * ) xSemaphore;
               
                       configASSERT( xSemaphore );
               
                       /* This function is called by xSemaphoreGetMutexHolder(), and should not
                        * be called directly.  Note:  This is a good way of determining if the
                        * calling task is the mutex holder, but not a good way of determining the
                        * identity of the mutex holder, as the holder may change between the
                        * following critical section exiting and the function returning. */
                       taskENTER_CRITICAL();
                       {
                           if( pxSemaphore->uxQueueType == queueQUEUE_IS_MUTEX )
                           {
                               pxReturn = pxSemaphore->u.xSemaphore.xMutexHolder;
                           }
                           else
                           {
                               pxReturn = NULL;
                           }
                       }
                       taskEXIT_CRITICAL();
               
                       return pxReturn;
                   } /*lint !e818 xSemaphore cannot be a pointer to const because it is a typedef. */
               
               #endif /* if ( ( configUSE_MUTEXES == 1 ) && ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) ) */
  608          /*-----------------------------------------------------------*/
  609          
  610          #if ( ( configUSE_MUTEXES == 1 ) && ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) )
               
                   TaskHandle_t xQueueGetMutexHolderFromISR( QueueHandle_t xSemaphore )
                   {
                       TaskHandle_t pxReturn;
               
                       configASSERT( xSemaphore );
               
                       /* Mutexes cannot be used in interrupt service routines, so the mutex
                        * holder should not change in an ISR, and therefore a critical section is
                        * not required here. */
                       if( ( ( Queue_t * ) xSemaphore )->uxQueueType == queueQUEUE_IS_MUTEX )
                       {
                           pxReturn = ( ( Queue_t * ) xSemaphore )->u.xSemaphore.xMutexHolder;
                       }
                       else
                       {
                           pxReturn = NULL;
                       }
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 11  

               
                       return pxReturn;
                   } /*lint !e818 xSemaphore cannot be a pointer to const because it is a typedef. */
               
               #endif /* if ( ( configUSE_MUTEXES == 1 ) && ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) ) */
  634          /*-----------------------------------------------------------*/
  635          
  636          #if ( configUSE_RECURSIVE_MUTEXES == 1 )
               
                   BaseType_t xQueueGiveMutexRecursive( QueueHandle_t xMutex )
                   {
                       BaseType_t xReturn;
                       Queue_t * const pxMutex = ( Queue_t * ) xMutex;
               
                       configASSERT( pxMutex );
               
                       /* If this is the task that holds the mutex then xMutexHolder will not
                        * change outside of this task.  If this task does not hold the mutex then
                        * pxMutexHolder can never coincidentally equal the tasks handle, and as
                        * this is the only condition we are interested in it does not matter if
                        * pxMutexHolder is accessed simultaneously by another task.  Therefore no
                        * mutual exclusion is required to test the pxMutexHolder variable. */
                       if( pxMutex->u.xSemaphore.xMutexHolder == xTaskGetCurrentTaskHandle() )
                       {
                           traceGIVE_MUTEX_RECURSIVE( pxMutex );
               
                           /* uxRecursiveCallCount cannot be zero if xMutexHolder is equal to
                            * the task handle, therefore no underflow check is required.  Also,
                            * uxRecursiveCallCount is only modified by the mutex holder, and as
                            * there can only be one, no mutual exclusion is required to modify the
                            * uxRecursiveCallCount member. */
                           ( pxMutex->u.xSemaphore.uxRecursiveCallCount )--;
               
                           /* Has the recursive call count unwound to 0? */
                           if( pxMutex->u.xSemaphore.uxRecursiveCallCount == ( UBaseType_t ) 0 )
                           {
                               /* Return the mutex.  This will automatically unblock any other
                                * task that might be waiting to access the mutex. */
                               ( void ) xQueueGenericSend( pxMutex, NULL, queueMUTEX_GIVE_BLOCK_TIME, queueSEND_TO_BACK 
             -);
                           }
                           else
                           {
                               mtCOVERAGE_TEST_MARKER();
                           }
               
                           xReturn = pdPASS;
                       }
                       else
                       {
                           /* The mutex cannot be given because the calling task is not the
                            * holder. */
                           xReturn = pdFAIL;
               
                           traceGIVE_MUTEX_RECURSIVE_FAILED( pxMutex );
                       }
               
                       return xReturn;
                   }
               
               #endif /* configUSE_RECURSIVE_MUTEXES */
  689          /*-----------------------------------------------------------*/
  690          
  691          #if ( configUSE_RECURSIVE_MUTEXES == 1 )
               
                   BaseType_t xQueueTakeMutexRecursive( QueueHandle_t xMutex,
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 12  

                                                        TickType_t xTicksToWait )
                   {
                       BaseType_t xReturn;
                       Queue_t * const pxMutex = ( Queue_t * ) xMutex;
               
                       configASSERT( pxMutex );
               
                       /* Comments regarding mutual exclusion as per those within
                        * xQueueGiveMutexRecursive(). */
               
                       traceTAKE_MUTEX_RECURSIVE( pxMutex );
               
                       if( pxMutex->u.xSemaphore.xMutexHolder == xTaskGetCurrentTaskHandle() )
                       {
                           ( pxMutex->u.xSemaphore.uxRecursiveCallCount )++;
                           xReturn = pdPASS;
                       }
                       else
                       {
                           xReturn = xQueueSemaphoreTake( pxMutex, xTicksToWait );
               
                           /* pdPASS will only be returned if the mutex was successfully
                            * obtained.  The calling task may have entered the Blocked state
                            * before reaching here. */
                           if( xReturn != pdFAIL )
                           {
                               ( pxMutex->u.xSemaphore.uxRecursiveCallCount )++;
                           }
                           else
                           {
                               traceTAKE_MUTEX_RECURSIVE_FAILED( pxMutex );
                           }
                       }
               
                       return xReturn;
                   }
               
               #endif /* configUSE_RECURSIVE_MUTEXES */
  732          /*-----------------------------------------------------------*/
  733          
  734          #if ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
               
                   QueueHandle_t xQueueCreateCountingSemaphoreStatic( const UBaseType_t uxMaxCount,
                                                                      const UBaseType_t uxInitialCount,
                                                                      StaticQueue_t * pxStaticQueue )
                   {
                       QueueHandle_t xHandle = NULL;
               
                       if( ( uxMaxCount != 0 ) &&
                           ( uxInitialCount <= uxMaxCount ) )
                       {
                           xHandle = xQueueGenericCreateStatic( uxMaxCount, queueSEMAPHORE_QUEUE_ITEM_LENGTH, NULL, pxSt
             -aticQueue, queueQUEUE_TYPE_COUNTING_SEMAPHORE );
               
                           if( xHandle != NULL )
                           {
                               ( ( Queue_t * ) xHandle )->uxMessagesWaiting = uxInitialCount;
               
                               traceCREATE_COUNTING_SEMAPHORE();
                           }
                           else
                           {
                               traceCREATE_COUNTING_SEMAPHORE_FAILED();
                           }
                       }
                       else
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 13  

                       {
                           configASSERT( xHandle );
                           mtCOVERAGE_TEST_MARKER();
                       }
               
                       return xHandle;
                   }
               
               #endif /* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
  768          /*-----------------------------------------------------------*/
  769          
  770          #if ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
               
                   QueueHandle_t xQueueCreateCountingSemaphore( const UBaseType_t uxMaxCount,
                                                                const UBaseType_t uxInitialCount )
                   {
                       QueueHandle_t xHandle = NULL;
               
                       if( ( uxMaxCount != 0 ) &&
                           ( uxInitialCount <= uxMaxCount ) )
                       {
                           xHandle = xQueueGenericCreate( uxMaxCount, queueSEMAPHORE_QUEUE_ITEM_LENGTH, queueQUEUE_TYPE_
             -COUNTING_SEMAPHORE );
               
                           if( xHandle != NULL )
                           {
                               ( ( Queue_t * ) xHandle )->uxMessagesWaiting = uxInitialCount;
               
                               traceCREATE_COUNTING_SEMAPHORE();
                           }
                           else
                           {
                               traceCREATE_COUNTING_SEMAPHORE_FAILED();
                           }
                       }
                       else
                       {
                           configASSERT( xHandle );
                           mtCOVERAGE_TEST_MARKER();
                       }
               
                       return xHandle;
                   }
               
               #endif /* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
  803          /*-----------------------------------------------------------*/
  804          
  805          BaseType_t xQueueGenericSend( QueueHandle_t xQueue,
  806                                        const void * const pvItemToQueue,
  807                                        TickType_t xTicksToWait,
  808                                        const BaseType_t xCopyPosition )
  809          {
  810   1          BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;
  811   1          TimeOut_t xTimeOut;
  812   1          Queue_t * const pxQueue = xQueue;
  813   1      
  814   1          configASSERT( pxQueue );
  815   1          configASSERT( !( ( pvItemToQueue == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );
  816   1          configASSERT( !( ( xCopyPosition == queueOVERWRITE ) && ( pxQueue->uxLength != 1 ) ) );
  817   1          #if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
                       {
                           configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait !=
             - 0 ) ) );
                       }
                   #endif
  822   1      
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 14  

  823   1          /*lint -save -e904 This function relaxes the coding standard somewhat to
  824   1           * allow return statements within the function itself.  This is done in the
  825   1           * interest of execution time efficiency. */
  826   1          for( ; ; )
  827   1          {
  828   2              taskENTER_CRITICAL();
  829   2              {
  830   3                  /* Is there room on the queue now?  The running task must be the
  831   3                   * highest priority task wanting to access the queue.  If the head item
  832   3                   * in the queue is to be overwritten then it does not matter if the
  833   3                   * queue is full. */
  834   3                  if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE )
             - )
  835   3                  {
  836   4                      traceQUEUE_SEND( pxQueue );
  837   4      
  838   4                      #if ( configUSE_QUEUE_SETS == 1 )
                                   {
                                       const UBaseType_t uxPreviousMessagesWaiting = pxQueue->uxMessagesWaiting;
               
                                       xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
               
                                       if( pxQueue->pxQueueSetContainer != NULL )
                                       {
                                           if( ( xCopyPosition == queueOVERWRITE ) && ( uxPreviousMessagesWaiting != ( U
             -BaseType_t ) 0 ) )
                                           {
                                               /* Do not notify the queue set as an existing item
                                                * was overwritten in the queue so the number of items
                                                * in the queue has not changed. */
                                               mtCOVERAGE_TEST_MARKER();
                                           }
                                           else if( prvNotifyQueueSetContainer( pxQueue ) != pdFALSE )
                                           {
                                               /* The queue is a member of a queue set, and posting
                                                * to the queue set caused a higher priority task to
                                                * unblock. A context switch is required. */
                                               queueYIELD_IF_USING_PREEMPTION();
                                           }
                                           else
                                           {
                                               mtCOVERAGE_TEST_MARKER();
                                           }
                                       }
                                       else
                                       {
                                           /* If there was a task waiting for data to arrive on the
                                            * queue then unblock it now. */
                                           if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
                                           {
                                               if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != p
             -dFALSE )
                                               {
                                                   /* The unblocked task has a priority higher than
                                                    * our own so yield immediately.  Yes it is ok to
                                                    * do this from within the critical section - the
                                                    * kernel takes care of that. */
                                                   queueYIELD_IF_USING_PREEMPTION();
                                               }
                                               else
                                               {
                                                   mtCOVERAGE_TEST_MARKER();
                                               }
                                           }
                                           else if( xYieldRequired != pdFALSE )
                                           {
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 15  

                                               /* This path is a special case that will only get
                                                * executed if the task was holding multiple mutexes
                                                * and the mutexes were given back in an order that is
                                                * different to that in which they were taken. */
                                               queueYIELD_IF_USING_PREEMPTION();
                                           }
                                           else
                                           {
                                               mtCOVERAGE_TEST_MARKER();
                                           }
                                       }
                                   }
                               #else /* configUSE_QUEUE_SETS */
  899   4                          {
  900   5                              xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
  901   5      
  902   5                              /* If there was a task waiting for data to arrive on the
  903   5                               * queue then unblock it now. */
  904   5                              if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
  905   5                              {
  906   6                                  if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFAL
             -SE )
  907   6                                  {
  908   7                                      /* The unblocked task has a priority higher than
  909   7                                       * our own so yield immediately.  Yes it is ok to do
  910   7                                       * this from within the critical section - the kernel
  911   7                                       * takes care of that. */
  912   7                                      queueYIELD_IF_USING_PREEMPTION();
  913   7                                  }
  914   6                                  else
  915   6                                  {
  916   7                                      mtCOVERAGE_TEST_MARKER();
  917   7                                  }
  918   6                              }
  919   5                              else if( xYieldRequired != pdFALSE )
  920   5                              {
  921   6                                  /* This path is a special case that will only get
  922   6                                   * executed if the task was holding multiple mutexes and
  923   6                                   * the mutexes were given back in an order that is
  924   6                                   * different to that in which they were taken. */
  925   6                                  queueYIELD_IF_USING_PREEMPTION();
  926   6                              }
  927   5                              else
  928   5                              {
  929   6                                  mtCOVERAGE_TEST_MARKER();
  930   6                              }
  931   5                          }
  932   4                      #endif /* configUSE_QUEUE_SETS */
  933   4      
  934   4                      taskEXIT_CRITICAL();
  935   4                      return pdPASS;
  936   4                  }
  937   3                  else
  938   3                  {
  939   4                      if( xTicksToWait == ( TickType_t ) 0 )
  940   4                      {
  941   5                          /* The queue was full and no block time is specified (or
  942   5                           * the block time has expired) so leave now. */
  943   5                          taskEXIT_CRITICAL();
  944   5      
  945   5                          /* Return to the original privilege level before exiting
  946   5                           * the function. */
  947   5                          traceQUEUE_SEND_FAILED( pxQueue );
  948   5                          return errQUEUE_FULL;
  949   5                      }
  950   4                      else if( xEntryTimeSet == pdFALSE )
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 16  

  951   4                      {
  952   5                          /* The queue was full and a block time was specified so
  953   5                           * configure the timeout structure. */
  954   5                          vTaskInternalSetTimeOutState( &xTimeOut );
  955   5                          xEntryTimeSet = pdTRUE;
  956   5                      }
  957   4                      else
  958   4                      {
  959   5                          /* Entry time was already set. */
  960   5                          mtCOVERAGE_TEST_MARKER();
  961   5                      }
  962   4                  }
  963   3              }
  964   2              taskEXIT_CRITICAL();
  965   2      
  966   2              /* Interrupts and other tasks can send to and receive from the queue
  967   2               * now the critical section has been exited. */
  968   2      
  969   2              vTaskSuspendAll();
  970   2              prvLockQueue( pxQueue );
  971   2      
  972   2              /* Update the timeout state to see if it has expired yet. */
  973   2              if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
  974   2              {
  975   3                  if( prvIsQueueFull( pxQueue ) != pdFALSE )
  976   3                  {
  977   4                      traceBLOCKING_ON_QUEUE_SEND( pxQueue );
  978   4                      vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
  979   4      
  980   4                      /* Unlocking the queue means queue events can effect the
  981   4                       * event list. It is possible that interrupts occurring now
  982   4                       * remove this task from the event list again - but as the
  983   4                       * scheduler is suspended the task will go onto the pending
  984   4                       * ready list instead of the actual ready list. */
  985   4                      prvUnlockQueue( pxQueue );
  986   4      
  987   4                      /* Resuming the scheduler will move tasks from the pending
  988   4                       * ready list into the ready list - so it is feasible that this
  989   4                       * task is already in the ready list before it yields - in which
  990   4                       * case the yield will not cause a context switch unless there
  991   4                       * is also a higher priority task in the pending ready list. */
  992   4                      if( xTaskResumeAll() == pdFALSE )
  993   4                      {
  994   5                          portYIELD_WITHIN_API();
  995   5                      }
  996   4                  }
  997   3                  else
  998   3                  {
  999   4                      /* Try again. */
 1000   4                      prvUnlockQueue( pxQueue );
 1001   4                      ( void ) xTaskResumeAll();
 1002   4                  }
 1003   3              }
 1004   2              else
 1005   2              {
 1006   3                  /* The timeout has expired. */
 1007   3                  prvUnlockQueue( pxQueue );
 1008   3                  ( void ) xTaskResumeAll();
 1009   3      
 1010   3                  traceQUEUE_SEND_FAILED( pxQueue );
 1011   3                  return errQUEUE_FULL;
 1012   3              }
 1013   2          } /*lint -restore */
 1014   1      }
 1015          /*-----------------------------------------------------------*/
 1016          
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 17  

 1017          BaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue,
 1018                                               const void * const pvItemToQueue,
 1019                                               BaseType_t * const pxHigherPriorityTaskWoken,
 1020                                               const BaseType_t xCopyPosition )
 1021          {
 1022   1          BaseType_t xReturn;
 1023   1          UBaseType_t uxSavedInterruptStatus;
 1024   1          Queue_t * const pxQueue = xQueue;
 1025   1      
 1026   1          configASSERT( pxQueue );
 1027   1          configASSERT( !( ( pvItemToQueue == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );
 1028   1          configASSERT( !( ( xCopyPosition == queueOVERWRITE ) && ( pxQueue->uxLength != 1 ) ) );
 1029   1      
 1030   1          /* RTOS ports that support interrupt nesting have the concept of a maximum
 1031   1           * system call (or maximum API call) interrupt priority.  Interrupts that are
 1032   1           * above the maximum system call priority are kept permanently enabled, even
 1033   1           * when the RTOS kernel is in a critical section, but cannot make any calls to
 1034   1           * FreeRTOS API functions.  If configASSERT() is defined in FreeRTOSConfig.h
 1035   1           * then portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion
 1036   1           * failure if a FreeRTOS API function is called from an interrupt that has been
 1037   1           * assigned a priority above the configured maximum system call priority.
 1038   1           * Only FreeRTOS functions that end in FromISR can be called from interrupts
 1039   1           * that have been assigned a priority at or (logically) below the maximum
 1040   1           * system call interrupt priority.  FreeRTOS maintains a separate interrupt
 1041   1           * safe API to ensure interrupt entry is as fast and as simple as possible.
 1042   1           * More information (albeit Cortex-M specific) is provided on the following
 1043   1           * link: https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */
 1044   1          portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
 1045   1      
 1046   1          /* Similar to xQueueGenericSend, except without blocking if there is no room
 1047   1           * in the queue.  Also don't directly wake a task that was blocked on a queue
 1048   1           * read, instead return a flag to say whether a context switch is required or
 1049   1           * not (i.e. has a task with a higher priority than us been woken by this
 1050   1           * post). */
 1051   1          uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
 1052   1          {
 1053   2              if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
 1054   2              {
 1055   3                  const int8_t cTxLock = pxQueue->cTxLock;
 1056   3                  const UBaseType_t uxPreviousMessagesWaiting = pxQueue->uxMessagesWaiting;
 1057   3      
 1058   3                  traceQUEUE_SEND_FROM_ISR( pxQueue );
 1059   3      
 1060   3                  /* Semaphores use xQueueGiveFromISR(), so pxQueue will not be a
 1061   3                   *  semaphore or mutex.  That means prvCopyDataToQueue() cannot result
 1062   3                   *  in a task disinheriting a priority and prvCopyDataToQueue() can be
 1063   3                   *  called here even though the disinherit function does not check if
 1064   3                   *  the scheduler is suspended before accessing the ready lists. */
 1065   3                  ( void ) prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
 1066   3      
 1067   3                  /* The event list is not altered if the queue is locked.  This will
 1068   3                   * be done when the queue is unlocked later. */
 1069   3                  if( cTxLock == queueUNLOCKED )
 1070   3                  {
 1071   4                      #if ( configUSE_QUEUE_SETS == 1 )
                                   {
                                       if( pxQueue->pxQueueSetContainer != NULL )
                                       {
                                           if( ( xCopyPosition == queueOVERWRITE ) && ( uxPreviousMessagesWaiting != ( U
             -BaseType_t ) 0 ) )
                                           {
                                               /* Do not notify the queue set as an existing item
                                                * was overwritten in the queue so the number of items
                                                * in the queue has not changed. */
                                               mtCOVERAGE_TEST_MARKER();
                                           }
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 18  

                                           else if( prvNotifyQueueSetContainer( pxQueue ) != pdFALSE )
                                           {
                                               /* The queue is a member of a queue set, and posting
                                                * to the queue set caused a higher priority task to
                                                * unblock.  A context switch is required. */
                                               if( pxHigherPriorityTaskWoken != NULL )
                                               {
                                                   *pxHigherPriorityTaskWoken = pdTRUE;
                                               }
                                               else
                                               {
                                                   mtCOVERAGE_TEST_MARKER();
                                               }
                                           }
                                           else
                                           {
                                               mtCOVERAGE_TEST_MARKER();
                                           }
                                       }
                                       else
                                       {
                                           if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
                                           {
                                               if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != p
             -dFALSE )
                                               {
                                                   /* The task waiting has a higher priority so
                                                    *  record that a context switch is required. */
                                                   if( pxHigherPriorityTaskWoken != NULL )
                                                   {
                                                       *pxHigherPriorityTaskWoken = pdTRUE;
                                                   }
                                                   else
                                                   {
                                                       mtCOVERAGE_TEST_MARKER();
                                                   }
                                               }
                                               else
                                               {
                                                   mtCOVERAGE_TEST_MARKER();
                                               }
                                           }
                                           else
                                           {
                                               mtCOVERAGE_TEST_MARKER();
                                           }
                                       }
                                   }
                               #else /* configUSE_QUEUE_SETS */
 1130   4                          {
 1131   5                              if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
 1132   5                              {
 1133   6                                  if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFAL
             -SE )
 1134   6                                  {
 1135   7                                      /* The task waiting has a higher priority so record that a
 1136   7                                       * context switch is required. */
 1137   7                                      if( pxHigherPriorityTaskWoken != NULL )
 1138   7                                      {
 1139   8                                          *pxHigherPriorityTaskWoken = pdTRUE;
 1140   8                                      }
 1141   7                                      else
 1142   7                                      {
 1143   8                                          mtCOVERAGE_TEST_MARKER();
 1144   8                                      }
 1145   7                                  }
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 19  

 1146   6                                  else
 1147   6                                  {
 1148   7                                      mtCOVERAGE_TEST_MARKER();
 1149   7                                  }
 1150   6                              }
 1151   5                              else
 1152   5                              {
 1153   6                                  mtCOVERAGE_TEST_MARKER();
 1154   6                              }
 1155   5      
 1156   5                              /* Not used in this path. */
 1157   5                              UNUSED( uxPreviousMessagesWaiting );
 1158   5                          }
 1159   4                      #endif /* configUSE_QUEUE_SETS */
 1160   4                  }
 1161   3                  else
 1162   3                  {
 1163   4                      /* Increment the lock count so the task that unlocks the queue
 1164   4                       * knows that data was posted while it was locked. */
 1165   4                      configASSERT( cTxLock != queueINT8_MAX );
 1166   4      
 1167   4                      pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
 1168   4                  }
 1169   3      
 1170   3                  xReturn = pdPASS;
 1171   3              }
 1172   2              else
 1173   2              {
 1174   3                  traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
 1175   3                  xReturn = errQUEUE_FULL;
 1176   3              }
 1177   2          }
 1178   1          portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
 1179   1      
 1180   1          return xReturn;
 1181   1      }
 1182          /*-----------------------------------------------------------*/
 1183          
 1184          BaseType_t xQueueGiveFromISR( QueueHandle_t xQueue,
 1185                                        BaseType_t * const pxHigherPriorityTaskWoken )
 1186          {
 1187   1          BaseType_t xReturn;
 1188   1          UBaseType_t uxSavedInterruptStatus;
 1189   1          Queue_t * const pxQueue = xQueue;
 1190   1      
 1191   1          /* Similar to xQueueGenericSendFromISR() but used with semaphores where the
 1192   1           * item size is 0.  Don't directly wake a task that was blocked on a queue
 1193   1           * read, instead return a flag to say whether a context switch is required or
 1194   1           * not (i.e. has a task with a higher priority than us been woken by this
 1195   1           * post). */
 1196   1      
 1197   1          configASSERT( pxQueue );
 1198   1      
 1199   1          /* xQueueGenericSendFromISR() should be used instead of xQueueGiveFromISR()
 1200   1           * if the item size is not 0. */
 1201   1          configASSERT( pxQueue->uxItemSize == 0 );
 1202   1      
 1203   1          /* Normally a mutex would not be given from an interrupt, especially if
 1204   1           * there is a mutex holder, as priority inheritance makes no sense for an
 1205   1           * interrupts, only tasks. */
 1206   1          configASSERT( !( ( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX ) && ( pxQueue->u.xSemaphore.xMutexHol
             -der != NULL ) ) );
 1207   1      
 1208   1          /* RTOS ports that support interrupt nesting have the concept of a maximum
 1209   1           * system call (or maximum API call) interrupt priority.  Interrupts that are
 1210   1           * above the maximum system call priority are kept permanently enabled, even
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 20  

 1211   1           * when the RTOS kernel is in a critical section, but cannot make any calls to
 1212   1           * FreeRTOS API functions.  If configASSERT() is defined in FreeRTOSConfig.h
 1213   1           * then portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion
 1214   1           * failure if a FreeRTOS API function is called from an interrupt that has been
 1215   1           * assigned a priority above the configured maximum system call priority.
 1216   1           * Only FreeRTOS functions that end in FromISR can be called from interrupts
 1217   1           * that have been assigned a priority at or (logically) below the maximum
 1218   1           * system call interrupt priority.  FreeRTOS maintains a separate interrupt
 1219   1           * safe API to ensure interrupt entry is as fast and as simple as possible.
 1220   1           * More information (albeit Cortex-M specific) is provided on the following
 1221   1           * link: https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */
 1222   1          portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
 1223   1      
 1224   1          uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
 1225   1          {
 1226   2              const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
 1227   2      
 1228   2              /* When the queue is used to implement a semaphore no data is ever
 1229   2               * moved through the queue but it is still valid to see if the queue 'has
 1230   2               * space'. */
 1231   2              if( uxMessagesWaiting < pxQueue->uxLength )
 1232   2              {
 1233   3                  const int8_t cTxLock = pxQueue->cTxLock;
 1234   3      
 1235   3                  traceQUEUE_SEND_FROM_ISR( pxQueue );
 1236   3      
 1237   3                  /* A task can only have an inherited priority if it is a mutex
 1238   3                   * holder - and if there is a mutex holder then the mutex cannot be
 1239   3                   * given from an ISR.  As this is the ISR version of the function it
 1240   3                   * can be assumed there is no mutex holder and no need to determine if
 1241   3                   * priority disinheritance is needed.  Simply increase the count of
 1242   3                   * messages (semaphores) available. */
 1243   3                  pxQueue->uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
 1244   3      
 1245   3                  /* The event list is not altered if the queue is locked.  This will
 1246   3                   * be done when the queue is unlocked later. */
 1247   3                  if( cTxLock == queueUNLOCKED )
 1248   3                  {
 1249   4                      #if ( configUSE_QUEUE_SETS == 1 )
                                   {
                                       if( pxQueue->pxQueueSetContainer != NULL )
                                       {
                                           if( prvNotifyQueueSetContainer( pxQueue ) != pdFALSE )
                                           {
                                               /* The semaphore is a member of a queue set, and
                                                * posting to the queue set caused a higher priority
                                                * task to unblock.  A context switch is required. */
                                               if( pxHigherPriorityTaskWoken != NULL )
                                               {
                                                   *pxHigherPriorityTaskWoken = pdTRUE;
                                               }
                                               else
                                               {
                                                   mtCOVERAGE_TEST_MARKER();
                                               }
                                           }
                                           else
                                           {
                                               mtCOVERAGE_TEST_MARKER();
                                           }
                                       }
                                       else
                                       {
                                           if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
                                           {
                                               if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != p
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 21  

             -dFALSE )
                                               {
                                                   /* The task waiting has a higher priority so
                                                    *  record that a context switch is required. */
                                                   if( pxHigherPriorityTaskWoken != NULL )
                                                   {
                                                       *pxHigherPriorityTaskWoken = pdTRUE;
                                                   }
                                                   else
                                                   {
                                                       mtCOVERAGE_TEST_MARKER();
                                                   }
                                               }
                                               else
                                               {
                                                   mtCOVERAGE_TEST_MARKER();
                                               }
                                           }
                                           else
                                           {
                                               mtCOVERAGE_TEST_MARKER();
                                           }
                                       }
                                   }
                               #else /* configUSE_QUEUE_SETS */
 1301   4                          {
 1302   5                              if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
 1303   5                              {
 1304   6                                  if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFAL
             -SE )
 1305   6                                  {
 1306   7                                      /* The task waiting has a higher priority so record that a
 1307   7                                       * context switch is required. */
 1308   7                                      if( pxHigherPriorityTaskWoken != NULL )
 1309   7                                      {
 1310   8                                          *pxHigherPriorityTaskWoken = pdTRUE;
 1311   8                                      }
 1312   7                                      else
 1313   7                                      {
 1314   8                                          mtCOVERAGE_TEST_MARKER();
 1315   8                                      }
 1316   7                                  }
 1317   6                                  else
 1318   6                                  {
 1319   7                                      mtCOVERAGE_TEST_MARKER();
 1320   7                                  }
 1321   6                              }
 1322   5                              else
 1323   5                              {
 1324   6                                  mtCOVERAGE_TEST_MARKER();
 1325   6                              }
 1326   5                          }
 1327   4                      #endif /* configUSE_QUEUE_SETS */
 1328   4                  }
 1329   3                  else
 1330   3                  {
 1331   4                      /* Increment the lock count so the task that unlocks the queue
 1332   4                       * knows that data was posted while it was locked. */
 1333   4                      configASSERT( cTxLock != queueINT8_MAX );
 1334   4      
 1335   4                      pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
 1336   4                  }
 1337   3      
 1338   3                  xReturn = pdPASS;
 1339   3              }
 1340   2              else
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 22  

 1341   2              {
 1342   3                  traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
 1343   3                  xReturn = errQUEUE_FULL;
 1344   3              }
 1345   2          }
 1346   1          portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
 1347   1      
 1348   1          return xReturn;
 1349   1      }
 1350          /*-----------------------------------------------------------*/
 1351          
 1352          BaseType_t xQueueReceive( QueueHandle_t xQueue,
 1353                                    void * const pvBuffer,
 1354                                    TickType_t xTicksToWait )
 1355          {
 1356   1          BaseType_t xEntryTimeSet = pdFALSE;
 1357   1          TimeOut_t xTimeOut;
 1358   1          Queue_t * const pxQueue = xQueue;
 1359   1      
 1360   1          /* Check the pointer is not NULL. */
 1361   1          configASSERT( ( pxQueue ) );
 1362   1      
 1363   1          /* The buffer into which data is received can only be NULL if the data size
 1364   1           * is zero (so no data is copied into the buffer). */
 1365   1          configASSERT( !( ( ( pvBuffer ) == NULL ) && ( ( pxQueue )->uxItemSize != ( UBaseType_t ) 0U ) ) );
 1366   1      
 1367   1          /* Cannot block if the scheduler is suspended. */
 1368   1          #if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
                       {
                           configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait !=
             - 0 ) ) );
                       }
                   #endif
 1373   1      
 1374   1          /*lint -save -e904  This function relaxes the coding standard somewhat to
 1375   1           * allow return statements within the function itself.  This is done in the
 1376   1           * interest of execution time efficiency. */
 1377   1          for( ; ; )
 1378   1          {
 1379   2              taskENTER_CRITICAL();
 1380   2              {
 1381   3                  const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
 1382   3      
 1383   3                  /* Is there data in the queue now?  To be running the calling task
 1384   3                   * must be the highest priority task wanting to access the queue. */
 1385   3                  if( uxMessagesWaiting > ( UBaseType_t ) 0 )
 1386   3                  {
 1387   4                      /* Data available, remove one item. */
 1388   4                      prvCopyDataFromQueue( pxQueue, pvBuffer );
 1389   4                      traceQUEUE_RECEIVE( pxQueue );
 1390   4                      pxQueue->uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
 1391   4      
 1392   4                      /* There is now space in the queue, were any tasks waiting to
 1393   4                       * post to the queue?  If so, unblock the highest priority waiting
 1394   4                       * task. */
 1395   4                      if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
 1396   4                      {
 1397   5                          if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
 1398   5                          {
 1399   6                              queueYIELD_IF_USING_PREEMPTION();
 1400   6                          }
 1401   5                          else
 1402   5                          {
 1403   6                              mtCOVERAGE_TEST_MARKER();
 1404   6                          }
 1405   5                      }
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 23  

 1406   4                      else
 1407   4                      {
 1408   5                          mtCOVERAGE_TEST_MARKER();
 1409   5                      }
 1410   4      
 1411   4                      taskEXIT_CRITICAL();
 1412   4                      return pdPASS;
 1413   4                  }
 1414   3                  else
 1415   3                  {
 1416   4                      if( xTicksToWait == ( TickType_t ) 0 )
 1417   4                      {
 1418   5                          /* The queue was empty and no block time is specified (or
 1419   5                           * the block time has expired) so leave now. */
 1420   5                          taskEXIT_CRITICAL();
 1421   5                          traceQUEUE_RECEIVE_FAILED( pxQueue );
 1422   5                          return errQUEUE_EMPTY;
 1423   5                      }
 1424   4                      else if( xEntryTimeSet == pdFALSE )
 1425   4                      {
 1426   5                          /* The queue was empty and a block time was specified so
 1427   5                           * configure the timeout structure. */
 1428   5                          vTaskInternalSetTimeOutState( &xTimeOut );
 1429   5                          xEntryTimeSet = pdTRUE;
 1430   5                      }
 1431   4                      else
 1432   4                      {
 1433   5                          /* Entry time was already set. */
 1434   5                          mtCOVERAGE_TEST_MARKER();
 1435   5                      }
 1436   4                  }
 1437   3              }
 1438   2              taskEXIT_CRITICAL();
 1439   2      
 1440   2              /* Interrupts and other tasks can send to and receive from the queue
 1441   2               * now the critical section has been exited. */
 1442   2      
 1443   2              vTaskSuspendAll();
 1444   2              prvLockQueue( pxQueue );
 1445   2      
 1446   2              /* Update the timeout state to see if it has expired yet. */
 1447   2              if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
 1448   2              {
 1449   3                  /* The timeout has not expired.  If the queue is still empty place
 1450   3                   * the task on the list of tasks waiting to receive from the queue. */
 1451   3                  if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
 1452   3                  {
 1453   4                      traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
 1454   4                      vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
 1455   4                      prvUnlockQueue( pxQueue );
 1456   4      
 1457   4                      if( xTaskResumeAll() == pdFALSE )
 1458   4                      {
 1459   5                          portYIELD_WITHIN_API();
 1460   5                      }
 1461   4                      else
 1462   4                      {
 1463   5                          mtCOVERAGE_TEST_MARKER();
 1464   5                      }
 1465   4                  }
 1466   3                  else
 1467   3                  {
 1468   4                      /* The queue contains data again.  Loop back to try and read the
 1469   4                       * data. */
 1470   4                      prvUnlockQueue( pxQueue );
 1471   4                      ( void ) xTaskResumeAll();
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 24  

 1472   4                  }
 1473   3              }
 1474   2              else
 1475   2              {
 1476   3                  /* Timed out.  If there is no data in the queue exit, otherwise loop
 1477   3                   * back and attempt to read the data. */
 1478   3                  prvUnlockQueue( pxQueue );
 1479   3                  ( void ) xTaskResumeAll();
 1480   3      
 1481   3                  if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
 1482   3                  {
 1483   4                      traceQUEUE_RECEIVE_FAILED( pxQueue );
 1484   4                      return errQUEUE_EMPTY;
 1485   4                  }
 1486   3                  else
 1487   3                  {
 1488   4                      mtCOVERAGE_TEST_MARKER();
 1489   4                  }
 1490   3              }
 1491   2          } /*lint -restore */
 1492   1      }
 1493          /*-----------------------------------------------------------*/
 1494          
 1495          BaseType_t xQueueSemaphoreTake( QueueHandle_t xQueue,
 1496                                          TickType_t xTicksToWait )
 1497          {
 1498   1          BaseType_t xEntryTimeSet = pdFALSE;
 1499   1          TimeOut_t xTimeOut;
 1500   1          Queue_t * const pxQueue = xQueue;
 1501   1      
 1502   1          #if ( configUSE_MUTEXES == 1 )
 1503   1              BaseType_t xInheritanceOccurred = pdFALSE;
 1504   1          #endif
 1505   1      
 1506   1          /* Check the queue pointer is not NULL. */
 1507   1          configASSERT( ( pxQueue ) );
 1508   1      
 1509   1          /* Check this really is a semaphore, in which case the item size will be
 1510   1           * 0. */
 1511   1          configASSERT( pxQueue->uxItemSize == 0 );
 1512   1      
 1513   1          /* Cannot block if the scheduler is suspended. */
 1514   1          #if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
                       {
                           configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait !=
             - 0 ) ) );
                       }
                   #endif
 1519   1      
 1520   1          /*lint -save -e904 This function relaxes the coding standard somewhat to allow return
 1521   1           * statements within the function itself.  This is done in the interest
 1522   1           * of execution time efficiency. */
 1523   1          for( ; ; )
 1524   1          {
 1525   2              taskENTER_CRITICAL();
 1526   2              {
 1527   3                  /* Semaphores are queues with an item size of 0, and where the
 1528   3                   * number of messages in the queue is the semaphore's count value. */
 1529   3                  const UBaseType_t uxSemaphoreCount = pxQueue->uxMessagesWaiting;
 1530   3      
 1531   3                  /* Is there data in the queue now?  To be running the calling task
 1532   3                   * must be the highest priority task wanting to access the queue. */
 1533   3                  if( uxSemaphoreCount > ( UBaseType_t ) 0 )
 1534   3                  {
 1535   4                      traceQUEUE_RECEIVE( pxQueue );
 1536   4      
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 25  

 1537   4                      /* Semaphores are queues with a data size of zero and where the
 1538   4                       * messages waiting is the semaphore's count.  Reduce the count. */
 1539   4                      pxQueue->uxMessagesWaiting = uxSemaphoreCount - ( UBaseType_t ) 1;
 1540   4      
 1541   4                      #if ( configUSE_MUTEXES == 1 )
 1542   4                          {
 1543   5                              if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
 1544   5                              {
 1545   6                                  /* Record the information required to implement
 1546   6                                   * priority inheritance should it become necessary. */
 1547   6                                  pxQueue->u.xSemaphore.xMutexHolder = pvTaskIncrementMutexHeldCount();
 1548   6                              }
 1549   5                              else
 1550   5                              {
 1551   6                                  mtCOVERAGE_TEST_MARKER();
 1552   6                              }
 1553   5                          }
 1554   4                      #endif /* configUSE_MUTEXES */
 1555   4      
 1556   4                      /* Check to see if other tasks are blocked waiting to give the
 1557   4                       * semaphore, and if so, unblock the highest priority such task. */
 1558   4                      if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
 1559   4                      {
 1560   5                          if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
 1561   5                          {
 1562   6                              queueYIELD_IF_USING_PREEMPTION();
 1563   6                          }
 1564   5                          else
 1565   5                          {
 1566   6                              mtCOVERAGE_TEST_MARKER();
 1567   6                          }
 1568   5                      }
 1569   4                      else
 1570   4                      {
 1571   5                          mtCOVERAGE_TEST_MARKER();
 1572   5                      }
 1573   4      
 1574   4                      taskEXIT_CRITICAL();
 1575   4                      return pdPASS;
 1576   4                  }
 1577   3                  else
 1578   3                  {
 1579   4                      if( xTicksToWait == ( TickType_t ) 0 )
 1580   4                      {
 1581   5                          /* For inheritance to have occurred there must have been an
 1582   5                           * initial timeout, and an adjusted timeout cannot become 0, as
 1583   5                           * if it were 0 the function would have exited. */
 1584   5                          #if ( configUSE_MUTEXES == 1 )
 1585   5                              {
 1586   6                                  configASSERT( xInheritanceOccurred == pdFALSE );
 1587   6                              }
 1588   5                          #endif /* configUSE_MUTEXES */
 1589   5      
 1590   5                          /* The semaphore count was 0 and no block time is specified
 1591   5                           * (or the block time has expired) so exit now. */
 1592   5                          taskEXIT_CRITICAL();
 1593   5                          traceQUEUE_RECEIVE_FAILED( pxQueue );
 1594   5                          return errQUEUE_EMPTY;
 1595   5                      }
 1596   4                      else if( xEntryTimeSet == pdFALSE )
 1597   4                      {
 1598   5                          /* The semaphore count was 0 and a block time was specified
 1599   5                           * so configure the timeout structure ready to block. */
 1600   5                          vTaskInternalSetTimeOutState( &xTimeOut );
 1601   5                          xEntryTimeSet = pdTRUE;
 1602   5                      }
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 26  

 1603   4                      else
 1604   4                      {
 1605   5                          /* Entry time was already set. */
 1606   5                          mtCOVERAGE_TEST_MARKER();
 1607   5                      }
 1608   4                  }
 1609   3              }
 1610   2              taskEXIT_CRITICAL();
 1611   2      
 1612   2              /* Interrupts and other tasks can give to and take from the semaphore
 1613   2               * now the critical section has been exited. */
 1614   2      
 1615   2              vTaskSuspendAll();
 1616   2              prvLockQueue( pxQueue );
 1617   2      
 1618   2              /* Update the timeout state to see if it has expired yet. */
 1619   2              if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
 1620   2              {
 1621   3                  /* A block time is specified and not expired.  If the semaphore
 1622   3                   * count is 0 then enter the Blocked state to wait for a semaphore to
 1623   3                   * become available.  As semaphores are implemented with queues the
 1624   3                   * queue being empty is equivalent to the semaphore count being 0. */
 1625   3                  if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
 1626   3                  {
 1627   4                      traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
 1628   4      
 1629   4                      #if ( configUSE_MUTEXES == 1 )
 1630   4                          {
 1631   5                              if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
 1632   5                              {
 1633   6                                  taskENTER_CRITICAL();
 1634   6                                  {
 1635   7                                      xInheritanceOccurred = xTaskPriorityInherit( pxQueue->u.xSemaphore.xMutex
             -Holder );
 1636   7                                  }
 1637   6                                  taskEXIT_CRITICAL();
 1638   6                              }
 1639   5                              else
 1640   5                              {
 1641   6                                  mtCOVERAGE_TEST_MARKER();
 1642   6                              }
 1643   5                          }
 1644   4                      #endif /* if ( configUSE_MUTEXES == 1 ) */
 1645   4      
 1646   4                      vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
 1647   4                      prvUnlockQueue( pxQueue );
 1648   4      
 1649   4                      if( xTaskResumeAll() == pdFALSE )
 1650   4                      {
 1651   5                          portYIELD_WITHIN_API();
 1652   5                      }
 1653   4                      else
 1654   4                      {
 1655   5                          mtCOVERAGE_TEST_MARKER();
 1656   5                      }
 1657   4                  }
 1658   3                  else
 1659   3                  {
 1660   4                      /* There was no timeout and the semaphore count was not 0, so
 1661   4                       * attempt to take the semaphore again. */
 1662   4                      prvUnlockQueue( pxQueue );
 1663   4                      ( void ) xTaskResumeAll();
 1664   4                  }
 1665   3              }
 1666   2              else
 1667   2              {
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 27  

 1668   3                  /* Timed out. */
 1669   3                  prvUnlockQueue( pxQueue );
 1670   3                  ( void ) xTaskResumeAll();
 1671   3      
 1672   3                  /* If the semaphore count is 0 exit now as the timeout has
 1673   3                   * expired.  Otherwise return to attempt to take the semaphore that is
 1674   3                   * known to be available.  As semaphores are implemented by queues the
 1675   3                   * queue being empty is equivalent to the semaphore count being 0. */
 1676   3                  if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
 1677   3                  {
 1678   4                      #if ( configUSE_MUTEXES == 1 )
 1679   4                          {
 1680   5                              /* xInheritanceOccurred could only have be set if
 1681   5                               * pxQueue->uxQueueType == queueQUEUE_IS_MUTEX so no need to
 1682   5                               * test the mutex type again to check it is actually a mutex. */
 1683   5                              if( xInheritanceOccurred != pdFALSE )
 1684   5                              {
 1685   6                                  taskENTER_CRITICAL();
 1686   6                                  {
 1687   7                                      UBaseType_t uxHighestWaitingPriority;
 1688   7      
 1689   7                                      /* This task blocking on the mutex caused another
 1690   7                                       * task to inherit this task's priority.  Now this task
 1691   7                                       * has timed out the priority should be disinherited
 1692   7                                       * again, but only as low as the next highest priority
 1693   7                                       * task that is waiting for the same mutex. */
 1694   7                                      uxHighestWaitingPriority = prvGetDisinheritPriorityAfterTimeout( pxQueue 
             -);
 1695   7                                      vTaskPriorityDisinheritAfterTimeout( pxQueue->u.xSemaphore.xMutexHolder, 
             -uxHighestWaitingPriority );
 1696   7                                  }
 1697   6                                  taskEXIT_CRITICAL();
 1698   6                              }
 1699   5                          }
 1700   4                      #endif /* configUSE_MUTEXES */
 1701   4      
 1702   4                      traceQUEUE_RECEIVE_FAILED( pxQueue );
 1703   4                      return errQUEUE_EMPTY;
 1704   4                  }
 1705   3                  else
 1706   3                  {
 1707   4                      mtCOVERAGE_TEST_MARKER();
 1708   4                  }
 1709   3              }
 1710   2          } /*lint -restore */
 1711   1      }
 1712          /*-----------------------------------------------------------*/
 1713          
 1714          BaseType_t xQueuePeek( QueueHandle_t xQueue,
 1715                                 void * const pvBuffer,
 1716                                 TickType_t xTicksToWait )
 1717          {
 1718   1          BaseType_t xEntryTimeSet = pdFALSE;
 1719   1          TimeOut_t xTimeOut;
 1720   1          int8_t * pcOriginalReadPosition;
 1721   1          Queue_t * const pxQueue = xQueue;
 1722   1      
 1723   1          /* Check the pointer is not NULL. */
 1724   1          configASSERT( ( pxQueue ) );
 1725   1      
 1726   1          /* The buffer into which data is received can only be NULL if the data size
 1727   1           * is zero (so no data is copied into the buffer. */
 1728   1          configASSERT( !( ( ( pvBuffer ) == NULL ) && ( ( pxQueue )->uxItemSize != ( UBaseType_t ) 0U ) ) );
 1729   1      
 1730   1          /* Cannot block if the scheduler is suspended. */
 1731   1          #if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 28  

                       {
                           configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait !=
             - 0 ) ) );
                       }
                   #endif
 1736   1      
 1737   1          /*lint -save -e904  This function relaxes the coding standard somewhat to
 1738   1           * allow return statements within the function itself.  This is done in the
 1739   1           * interest of execution time efficiency. */
 1740   1          for( ; ; )
 1741   1          {
 1742   2              taskENTER_CRITICAL();
 1743   2              {
 1744   3                  const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
 1745   3      
 1746   3                  /* Is there data in the queue now?  To be running the calling task
 1747   3                   * must be the highest priority task wanting to access the queue. */
 1748   3                  if( uxMessagesWaiting > ( UBaseType_t ) 0 )
 1749   3                  {
 1750   4                      /* Remember the read position so it can be reset after the data
 1751   4                       * is read from the queue as this function is only peeking the
 1752   4                       * data, not removing it. */
 1753   4                      pcOriginalReadPosition = pxQueue->u.xQueue.pcReadFrom;
 1754   4      
 1755   4                      prvCopyDataFromQueue( pxQueue, pvBuffer );
 1756   4                      traceQUEUE_PEEK( pxQueue );
 1757   4      
 1758   4                      /* The data is not being removed, so reset the read pointer. */
 1759   4                      pxQueue->u.xQueue.pcReadFrom = pcOriginalReadPosition;
 1760   4      
 1761   4                      /* The data is being left in the queue, so see if there are
 1762   4                       * any other tasks waiting for the data. */
 1763   4                      if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
 1764   4                      {
 1765   5                          if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
 1766   5                          {
 1767   6                              /* The task waiting has a higher priority than this task. */
 1768   6                              queueYIELD_IF_USING_PREEMPTION();
 1769   6                          }
 1770   5                          else
 1771   5                          {
 1772   6                              mtCOVERAGE_TEST_MARKER();
 1773   6                          }
 1774   5                      }
 1775   4                      else
 1776   4                      {
 1777   5                          mtCOVERAGE_TEST_MARKER();
 1778   5                      }
 1779   4      
 1780   4                      taskEXIT_CRITICAL();
 1781   4                      return pdPASS;
 1782   4                  }
 1783   3                  else
 1784   3                  {
 1785   4                      if( xTicksToWait == ( TickType_t ) 0 )
 1786   4                      {
 1787   5                          /* The queue was empty and no block time is specified (or
 1788   5                           * the block time has expired) so leave now. */
 1789   5                          taskEXIT_CRITICAL();
 1790   5                          traceQUEUE_PEEK_FAILED( pxQueue );
 1791   5                          return errQUEUE_EMPTY;
 1792   5                      }
 1793   4                      else if( xEntryTimeSet == pdFALSE )
 1794   4                      {
 1795   5                          /* The queue was empty and a block time was specified so
 1796   5                           * configure the timeout structure ready to enter the blocked
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 29  

 1797   5                           * state. */
 1798   5                          vTaskInternalSetTimeOutState( &xTimeOut );
 1799   5                          xEntryTimeSet = pdTRUE;
 1800   5                      }
 1801   4                      else
 1802   4                      {
 1803   5                          /* Entry time was already set. */
 1804   5                          mtCOVERAGE_TEST_MARKER();
 1805   5                      }
 1806   4                  }
 1807   3              }
 1808   2              taskEXIT_CRITICAL();
 1809   2      
 1810   2              /* Interrupts and other tasks can send to and receive from the queue
 1811   2               * now that the critical section has been exited. */
 1812   2      
 1813   2              vTaskSuspendAll();
 1814   2              prvLockQueue( pxQueue );
 1815   2      
 1816   2              /* Update the timeout state to see if it has expired yet. */
 1817   2              if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
 1818   2              {
 1819   3                  /* Timeout has not expired yet, check to see if there is data in the
 1820   3                  * queue now, and if not enter the Blocked state to wait for data. */
 1821   3                  if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
 1822   3                  {
 1823   4                      traceBLOCKING_ON_QUEUE_PEEK( pxQueue );
 1824   4                      vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
 1825   4                      prvUnlockQueue( pxQueue );
 1826   4      
 1827   4                      if( xTaskResumeAll() == pdFALSE )
 1828   4                      {
 1829   5                          portYIELD_WITHIN_API();
 1830   5                      }
 1831   4                      else
 1832   4                      {
 1833   5                          mtCOVERAGE_TEST_MARKER();
 1834   5                      }
 1835   4                  }
 1836   3                  else
 1837   3                  {
 1838   4                      /* There is data in the queue now, so don't enter the blocked
 1839   4                       * state, instead return to try and obtain the data. */
 1840   4                      prvUnlockQueue( pxQueue );
 1841   4                      ( void ) xTaskResumeAll();
 1842   4                  }
 1843   3              }
 1844   2              else
 1845   2              {
 1846   3                  /* The timeout has expired.  If there is still no data in the queue
 1847   3                   * exit, otherwise go back and try to read the data again. */
 1848   3                  prvUnlockQueue( pxQueue );
 1849   3                  ( void ) xTaskResumeAll();
 1850   3      
 1851   3                  if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
 1852   3                  {
 1853   4                      traceQUEUE_PEEK_FAILED( pxQueue );
 1854   4                      return errQUEUE_EMPTY;
 1855   4                  }
 1856   3                  else
 1857   3                  {
 1858   4                      mtCOVERAGE_TEST_MARKER();
 1859   4                  }
 1860   3              }
 1861   2          } /*lint -restore */
 1862   1      }
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 30  

 1863          /*-----------------------------------------------------------*/
 1864          
 1865          BaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue,
 1866                                           void * const pvBuffer,
 1867                                           BaseType_t * const pxHigherPriorityTaskWoken )
 1868          {
 1869   1          BaseType_t xReturn;
 1870   1          UBaseType_t uxSavedInterruptStatus;
 1871   1          Queue_t * const pxQueue = xQueue;
 1872   1      
 1873   1          configASSERT( pxQueue );
 1874   1          configASSERT( !( ( pvBuffer == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );
 1875   1      
 1876   1          /* RTOS ports that support interrupt nesting have the concept of a maximum
 1877   1           * system call (or maximum API call) interrupt priority.  Interrupts that are
 1878   1           * above the maximum system call priority are kept permanently enabled, even
 1879   1           * when the RTOS kernel is in a critical section, but cannot make any calls to
 1880   1           * FreeRTOS API functions.  If configASSERT() is defined in FreeRTOSConfig.h
 1881   1           * then portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion
 1882   1           * failure if a FreeRTOS API function is called from an interrupt that has been
 1883   1           * assigned a priority above the configured maximum system call priority.
 1884   1           * Only FreeRTOS functions that end in FromISR can be called from interrupts
 1885   1           * that have been assigned a priority at or (logically) below the maximum
 1886   1           * system call interrupt priority.  FreeRTOS maintains a separate interrupt
 1887   1           * safe API to ensure interrupt entry is as fast and as simple as possible.
 1888   1           * More information (albeit Cortex-M specific) is provided on the following
 1889   1           * link: https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */
 1890   1          portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
 1891   1      
 1892   1          uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
 1893   1          {
 1894   2              const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
 1895   2      
 1896   2              /* Cannot block in an ISR, so check there is data available. */
 1897   2              if( uxMessagesWaiting > ( UBaseType_t ) 0 )
 1898   2              {
 1899   3                  const int8_t cRxLock = pxQueue->cRxLock;
 1900   3      
 1901   3                  traceQUEUE_RECEIVE_FROM_ISR( pxQueue );
 1902   3      
 1903   3                  prvCopyDataFromQueue( pxQueue, pvBuffer );
 1904   3                  pxQueue->uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
 1905   3      
 1906   3                  /* If the queue is locked the event list will not be modified.
 1907   3                   * Instead update the lock count so the task that unlocks the queue
 1908   3                   * will know that an ISR has removed data while the queue was
 1909   3                   * locked. */
 1910   3                  if( cRxLock == queueUNLOCKED )
 1911   3                  {
 1912   4                      if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
 1913   4                      {
 1914   5                          if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
 1915   5                          {
 1916   6                              /* The task waiting has a higher priority than us so
 1917   6                               * force a context switch. */
 1918   6                              if( pxHigherPriorityTaskWoken != NULL )
 1919   6                              {
 1920   7                                  *pxHigherPriorityTaskWoken = pdTRUE;
 1921   7                              }
 1922   6                              else
 1923   6                              {
 1924   7                                  mtCOVERAGE_TEST_MARKER();
 1925   7                              }
 1926   6                          }
 1927   5                          else
 1928   5                          {
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 31  

 1929   6                              mtCOVERAGE_TEST_MARKER();
 1930   6                          }
 1931   5                      }
 1932   4                      else
 1933   4                      {
 1934   5                          mtCOVERAGE_TEST_MARKER();
 1935   5                      }
 1936   4                  }
 1937   3                  else
 1938   3                  {
 1939   4                      /* Increment the lock count so the task that unlocks the queue
 1940   4                       * knows that data was removed while it was locked. */
 1941   4                      configASSERT( cRxLock != queueINT8_MAX );
 1942   4      
 1943   4                      pxQueue->cRxLock = ( int8_t ) ( cRxLock + 1 );
 1944   4                  }
 1945   3      
 1946   3                  xReturn = pdPASS;
 1947   3              }
 1948   2              else
 1949   2              {
 1950   3                  xReturn = pdFAIL;
 1951   3                  traceQUEUE_RECEIVE_FROM_ISR_FAILED( pxQueue );
 1952   3              }
 1953   2          }
 1954   1          portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
 1955   1      
 1956   1          return xReturn;
 1957   1      }
 1958          /*-----------------------------------------------------------*/
 1959          
 1960          BaseType_t xQueuePeekFromISR( QueueHandle_t xQueue,
 1961                                        void * const pvBuffer )
 1962          {
 1963   1          BaseType_t xReturn;
 1964   1          UBaseType_t uxSavedInterruptStatus;
 1965   1          int8_t * pcOriginalReadPosition;
 1966   1          Queue_t * const pxQueue = xQueue;
 1967   1      
 1968   1          configASSERT( pxQueue );
 1969   1          configASSERT( !( ( pvBuffer == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );
 1970   1          configASSERT( pxQueue->uxItemSize != 0 ); /* Can't peek a semaphore. */
 1971   1      
 1972   1          /* RTOS ports that support interrupt nesting have the concept of a maximum
 1973   1           * system call (or maximum API call) interrupt priority.  Interrupts that are
 1974   1           * above the maximum system call priority are kept permanently enabled, even
 1975   1           * when the RTOS kernel is in a critical section, but cannot make any calls to
 1976   1           * FreeRTOS API functions.  If configASSERT() is defined in FreeRTOSConfig.h
 1977   1           * then portASSERT_IF_INTERRUPT_PRIORITY_INVALID() will result in an assertion
 1978   1           * failure if a FreeRTOS API function is called from an interrupt that has been
 1979   1           * assigned a priority above the configured maximum system call priority.
 1980   1           * Only FreeRTOS functions that end in FromISR can be called from interrupts
 1981   1           * that have been assigned a priority at or (logically) below the maximum
 1982   1           * system call interrupt priority.  FreeRTOS maintains a separate interrupt
 1983   1           * safe API to ensure interrupt entry is as fast and as simple as possible.
 1984   1           * More information (albeit Cortex-M specific) is provided on the following
 1985   1           * link: https://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html */
 1986   1          portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
 1987   1      
 1988   1          uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
 1989   1          {
 1990   2              /* Cannot block in an ISR, so check there is data available. */
 1991   2              if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
 1992   2              {
 1993   3                  traceQUEUE_PEEK_FROM_ISR( pxQueue );
 1994   3      
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 32  

 1995   3                  /* Remember the read position so it can be reset as nothing is
 1996   3                   * actually being removed from the queue. */
 1997   3                  pcOriginalReadPosition = pxQueue->u.xQueue.pcReadFrom;
 1998   3                  prvCopyDataFromQueue( pxQueue, pvBuffer );
 1999   3                  pxQueue->u.xQueue.pcReadFrom = pcOriginalReadPosition;
 2000   3      
 2001   3                  xReturn = pdPASS;
 2002   3              }
 2003   2              else
 2004   2              {
 2005   3                  xReturn = pdFAIL;
 2006   3                  traceQUEUE_PEEK_FROM_ISR_FAILED( pxQueue );
 2007   3              }
 2008   2          }
 2009   1          portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
 2010   1      
 2011   1          return xReturn;
 2012   1      }
 2013          /*-----------------------------------------------------------*/
 2014          
 2015          UBaseType_t uxQueueMessagesWaiting( const QueueHandle_t xQueue )
 2016          {
 2017   1          UBaseType_t uxReturn;
 2018   1      
 2019   1          configASSERT( xQueue );
 2020   1      
 2021   1          taskENTER_CRITICAL();
 2022   1          {
 2023   2              uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
 2024   2          }
 2025   1          taskEXIT_CRITICAL();
 2026   1      
 2027   1          return uxReturn;
 2028   1      } /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
 2029          /*-----------------------------------------------------------*/
 2030          
 2031          UBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue )
 2032          {
 2033   1          UBaseType_t uxReturn;
 2034   1          Queue_t * const pxQueue = xQueue;
 2035   1      
 2036   1          configASSERT( pxQueue );
 2037   1      
 2038   1          taskENTER_CRITICAL();
 2039   1          {
 2040   2              uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
 2041   2          }
 2042   1          taskEXIT_CRITICAL();
 2043   1      
 2044   1          return uxReturn;
 2045   1      } /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
 2046          /*-----------------------------------------------------------*/
 2047          
 2048          UBaseType_t uxQueueMessagesWaitingFromISR( const QueueHandle_t xQueue )
 2049          {
 2050   1          UBaseType_t uxReturn;
 2051   1          Queue_t * const pxQueue = xQueue;
 2052   1      
 2053   1          configASSERT( pxQueue );
 2054   1          uxReturn = pxQueue->uxMessagesWaiting;
 2055   1      
 2056   1          return uxReturn;
 2057   1      } /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
 2058          /*-----------------------------------------------------------*/
 2059          
 2060          void vQueueDelete( QueueHandle_t xQueue )
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 33  

 2061          {
 2062   1          Queue_t * const pxQueue = xQueue;
 2063   1      
 2064   1          configASSERT( pxQueue );
 2065   1          traceQUEUE_DELETE( pxQueue );
 2066   1      
 2067   1          #if ( configQUEUE_REGISTRY_SIZE > 0 )
                       {
                           vQueueUnregisterQueue( pxQueue );
                       }
                   #endif
 2072   1      
 2073   1          #if ( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
 2074   1              {
 2075   2                  /* The queue can only have been allocated dynamically - free it
 2076   2                   * again. */
 2077   2                  vPortFree( pxQueue );
 2078   2              }
 2079   1          #elif ( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
                       {
                           /* The queue could have been allocated statically or dynamically, so
                            * check before attempting to free the memory. */
                           if( pxQueue->ucStaticallyAllocated == ( uint8_t ) pdFALSE )
                           {
                               vPortFree( pxQueue );
                           }
                           else
                           {
                               mtCOVERAGE_TEST_MARKER();
                           }
                       }
                   #else /* if ( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
             - */
                       {
                           /* The queue must have been statically allocated, so is not going to be
                            * deleted.  Avoid compiler warnings about the unused parameter. */
                           ( void ) pxQueue;
                       }
                   #endif /* configSUPPORT_DYNAMIC_ALLOCATION */
 2099   1      }
 2100          /*-----------------------------------------------------------*/
 2101          
 2102          #if ( configUSE_TRACE_FACILITY == 1 )
               
                   UBaseType_t uxQueueGetQueueNumber( QueueHandle_t xQueue )
                   {
                       return ( ( Queue_t * ) xQueue )->uxQueueNumber;
                   }
               
               #endif /* configUSE_TRACE_FACILITY */
 2110          /*-----------------------------------------------------------*/
 2111          
 2112          #if ( configUSE_TRACE_FACILITY == 1 )
               
                   void vQueueSetQueueNumber( QueueHandle_t xQueue,
                                              UBaseType_t uxQueueNumber )
                   {
                       ( ( Queue_t * ) xQueue )->uxQueueNumber = uxQueueNumber;
                   }
               
               #endif /* configUSE_TRACE_FACILITY */
 2121          /*-----------------------------------------------------------*/
 2122          
 2123          #if ( configUSE_TRACE_FACILITY == 1 )
               
                   uint8_t ucQueueGetQueueType( QueueHandle_t xQueue )
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 34  

                   {
                       return ( ( Queue_t * ) xQueue )->ucQueueType;
                   }
               
               #endif /* configUSE_TRACE_FACILITY */
 2131          /*-----------------------------------------------------------*/
 2132          
 2133          #if ( configUSE_MUTEXES == 1 )
 2134          
 2135              static UBaseType_t prvGetDisinheritPriorityAfterTimeout( const Queue_t * const pxQueue )
 2136              {
 2137   1              UBaseType_t uxHighestPriorityOfWaitingTasks;
 2138   1      
 2139   1              /* If a task waiting for a mutex causes the mutex holder to inherit a
 2140   1               * priority, but the waiting task times out, then the holder should
 2141   1               * disinherit the priority - but only down to the highest priority of any
 2142   1               * other tasks that are waiting for the same mutex.  For this purpose,
 2143   1               * return the priority of the highest priority task that is waiting for the
 2144   1               * mutex. */
 2145   1              if( listCURRENT_LIST_LENGTH( &( pxQueue->xTasksWaitingToReceive ) ) > 0U )
 2146   1              {
 2147   2                  uxHighestPriorityOfWaitingTasks = ( UBaseType_t ) configMAX_PRIORITIES - ( UBaseType_t ) list
             -GET_ITEM_VALUE_OF_HEAD_ENTRY( &( pxQueue->xTasksWaitingToReceive ) );
 2148   2              }
 2149   1              else
 2150   1              {
 2151   2                  uxHighestPriorityOfWaitingTasks = tskIDLE_PRIORITY;
 2152   2              }
 2153   1      
 2154   1              return uxHighestPriorityOfWaitingTasks;
 2155   1          }
 2156          
 2157          #endif /* configUSE_MUTEXES */
 2158          /*-----------------------------------------------------------*/
 2159          
 2160          static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue,
 2161                                                const void * pvItemToQueue,
 2162                                                const BaseType_t xPosition )
 2163          {
 2164   1          BaseType_t xReturn = pdFALSE;
 2165   1          UBaseType_t uxMessagesWaiting;
 2166   1      
 2167   1          /* This function is called from a critical section. */
 2168   1      
 2169   1          uxMessagesWaiting = pxQueue->uxMessagesWaiting;
 2170   1      
 2171   1          if( pxQueue->uxItemSize == ( UBaseType_t ) 0 )
 2172   1          {
 2173   2              #if ( configUSE_MUTEXES == 1 )
 2174   2                  {
 2175   3                      if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
 2176   3                      {
 2177   4                          /* The mutex is no longer being held. */
 2178   4                          xReturn = xTaskPriorityDisinherit( pxQueue->u.xSemaphore.xMutexHolder );
 2179   4                          pxQueue->u.xSemaphore.xMutexHolder = NULL;
 2180   4                      }
 2181   3                      else
 2182   3                      {
 2183   4                          mtCOVERAGE_TEST_MARKER();
 2184   4                      }
 2185   3                  }
 2186   2              #endif /* configUSE_MUTEXES */
 2187   2          }
 2188   1          else if( xPosition == queueSEND_TO_BACK )
 2189   1          {
 2190   2              ( void ) memcpy( ( void * ) pxQueue->pcWriteTo, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); 
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 35  

             -/*lint !e961 !e418 !e9087 MISRA exception as the casts are only redundant for some ports, plus previous logic ensures a 
             -null pointer can only be passed to memcpy() if the copy size is 0.  Cast to void required by function signature and safe
             - as no alignment requirement and copy length specified in bytes. */
 2191   2              pxQueue->pcWriteTo += pxQueue->uxItemSize;                                                       
             -/*lint !e9016 Pointer arithmetic on char types ok, especially in this use case where it is the clearest way of conveying
             - intent. */
 2192   2      
 2193   2              if( pxQueue->pcWriteTo >= pxQueue->u.xQueue.pcTail )                                             
             -/*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
 2194   2              {
 2195   3                  pxQueue->pcWriteTo = pxQueue->pcHead;
 2196   3              }
 2197   2              else
 2198   2              {
 2199   3                  mtCOVERAGE_TEST_MARKER();
 2200   3              }
 2201   2          }
 2202   1          else
 2203   1          {
 2204   2              ( void ) memcpy( ( void * ) pxQueue->u.xQueue.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue->uxIt
             -emSize ); /*lint !e961 !e9087 !e418 MISRA exception as the casts are only redundant for some ports.  Cast to void requir
             -ed by function signature and safe as no alignment requirement and copy length specified in bytes.  Assert checks null po
             -inter only used when length is 0. */
 2205   2              pxQueue->u.xQueue.pcReadFrom -= pxQueue->uxItemSize;
 2206   2      
 2207   2              if( pxQueue->u.xQueue.pcReadFrom < pxQueue->pcHead ) /*lint !e946 MISRA exception justified as co
             -mparison of pointers is the cleanest solution. */
 2208   2              {
 2209   3                  pxQueue->u.xQueue.pcReadFrom = ( pxQueue->u.xQueue.pcTail - pxQueue->uxItemSize );
 2210   3              }
 2211   2              else
 2212   2              {
 2213   3                  mtCOVERAGE_TEST_MARKER();
 2214   3              }
 2215   2      
 2216   2              if( xPosition == queueOVERWRITE )
 2217   2              {
 2218   3                  if( uxMessagesWaiting > ( UBaseType_t ) 0 )
 2219   3                  {
 2220   4                      /* An item is not being added but overwritten, so subtract
 2221   4                       * one from the recorded number of items in the queue so when
 2222   4                       * one is added again below the number of recorded items remains
 2223   4                       * correct. */
 2224   4                      --uxMessagesWaiting;
 2225   4                  }
 2226   3                  else
 2227   3                  {
 2228   4                      mtCOVERAGE_TEST_MARKER();
 2229   4                  }
 2230   3              }
 2231   2              else
 2232   2              {
 2233   3                  mtCOVERAGE_TEST_MARKER();
 2234   3              }
 2235   2          }
 2236   1      
 2237   1          pxQueue->uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
 2238   1      
 2239   1          return xReturn;
 2240   1      }
 2241          /*-----------------------------------------------------------*/
 2242          
 2243          static void prvCopyDataFromQueue( Queue_t * const pxQueue,
 2244                                            void * const pvBuffer )
 2245          {
 2246   1          if( pxQueue->uxItemSize != ( UBaseType_t ) 0 )
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 36  

 2247   1          {
 2248   2              pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize;           /*lint !e9016 Pointer arithmetic o
             -n char types ok, especially in this use case where it is the clearest way of conveying intent. */
 2249   2      
 2250   2              if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail ) /*lint !e946 MISRA exception justi
             -fied as use of the relational operator is the cleanest solutions. */
 2251   2              {
 2252   3                  pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;
 2253   3              }
 2254   2              else
 2255   2              {
 2256   3                  mtCOVERAGE_TEST_MARKER();
 2257   3              }
 2258   2      
 2259   2              ( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( size_t ) pxQueue
             -->uxItemSize ); /*lint !e961 !e418 !e9087 MISRA exception as the casts are only redundant for some ports.  Also previous
             - logic ensures a null pointer can only be passed to memcpy() when the count is 0.  Cast to void required by function sig
             -nature and safe as no alignment requirement and copy length specified in bytes. */
 2260   2          }
 2261   1      }
 2262          /*-----------------------------------------------------------*/
 2263          
 2264          static void prvUnlockQueue( Queue_t * const pxQueue )
 2265          {
 2266   1          /* THIS FUNCTION MUST BE CALLED WITH THE SCHEDULER SUSPENDED. */
 2267   1      
 2268   1          /* The lock counts contains the number of extra data items placed or
 2269   1           * removed from the queue while the queue was locked.  When a queue is
 2270   1           * locked items can be added or removed, but the event lists cannot be
 2271   1           * updated. */
 2272   1          taskENTER_CRITICAL();
 2273   1          {
 2274   2              int8_t cTxLock = pxQueue->cTxLock;
 2275   2      
 2276   2              /* See if data was added to the queue while it was locked. */
 2277   2              while( cTxLock > queueLOCKED_UNMODIFIED )
 2278   2              {
 2279   3                  /* Data was posted while the queue was locked.  Are any tasks
 2280   3                   * blocked waiting for data to become available? */
 2281   3                  #if ( configUSE_QUEUE_SETS == 1 )
                               {
                                   if( pxQueue->pxQueueSetContainer != NULL )
                                   {
                                       if( prvNotifyQueueSetContainer( pxQueue ) != pdFALSE )
                                       {
                                           /* The queue is a member of a queue set, and posting to
                                            * the queue set caused a higher priority task to unblock.
                                            * A context switch is required. */
                                           vTaskMissedYield();
                                       }
                                       else
                                       {
                                           mtCOVERAGE_TEST_MARKER();
                                       }
                                   }
                                   else
                                   {
                                       /* Tasks that are removed from the event list will get
                                        * added to the pending ready list as the scheduler is still
                                        * suspended. */
                                       if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
                                       {
                                           if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFAL
             -SE )
                                           {
                                               /* The task waiting has a higher priority so record that a
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 37  

                                                * context switch is required. */
                                               vTaskMissedYield();
                                           }
                                           else
                                           {
                                               mtCOVERAGE_TEST_MARKER();
                                           }
                                       }
                                       else
                                       {
                                           break;
                                       }
                                   }
                               }
                           #else /* configUSE_QUEUE_SETS */
 2322   3                      {
 2323   4                          /* Tasks that are removed from the event list will get added to
 2324   4                           * the pending ready list as the scheduler is still suspended. */
 2325   4                          if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
 2326   4                          {
 2327   5                              if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
 2328   5                              {
 2329   6                                  /* The task waiting has a higher priority so record that
 2330   6                                   * a context switch is required. */
 2331   6                                  vTaskMissedYield();
 2332   6                              }
 2333   5                              else
 2334   5                              {
 2335   6                                  mtCOVERAGE_TEST_MARKER();
 2336   6                              }
 2337   5                          }
 2338   4                          else
 2339   4                          {
 2340   5                              break;
 2341   5                          }
 2342   4                      }
 2343   3                  #endif /* configUSE_QUEUE_SETS */
 2344   3      
 2345   3                  --cTxLock;
 2346   3              }
 2347   2      
 2348   2              pxQueue->cTxLock = queueUNLOCKED;
 2349   2          }
 2350   1          taskEXIT_CRITICAL();
 2351   1      
 2352   1          /* Do the same for the Rx lock. */
 2353   1          taskENTER_CRITICAL();
 2354   1          {
 2355   2              int8_t cRxLock = pxQueue->cRxLock;
 2356   2      
 2357   2              while( cRxLock > queueLOCKED_UNMODIFIED )
 2358   2              {
 2359   3                  if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
 2360   3                  {
 2361   4                      if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
 2362   4                      {
 2363   5                          vTaskMissedYield();
 2364   5                      }
 2365   4                      else
 2366   4                      {
 2367   5                          mtCOVERAGE_TEST_MARKER();
 2368   5                      }
 2369   4      
 2370   4                      --cRxLock;
 2371   4                  }
 2372   3                  else
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 38  

 2373   3                  {
 2374   4                      break;
 2375   4                  }
 2376   3              }
 2377   2      
 2378   2              pxQueue->cRxLock = queueUNLOCKED;
 2379   2          }
 2380   1          taskEXIT_CRITICAL();
 2381   1      }
 2382          /*-----------------------------------------------------------*/
 2383          
 2384          static BaseType_t prvIsQueueEmpty( const Queue_t * pxQueue )
 2385          {
 2386   1          BaseType_t xReturn;
 2387   1      
 2388   1          taskENTER_CRITICAL();
 2389   1          {
 2390   2              if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0 )
 2391   2              {
 2392   3                  xReturn = pdTRUE;
 2393   3              }
 2394   2              else
 2395   2              {
 2396   3                  xReturn = pdFALSE;
 2397   3              }
 2398   2          }
 2399   1          taskEXIT_CRITICAL();
 2400   1      
 2401   1          return xReturn;
 2402   1      }
 2403          /*-----------------------------------------------------------*/
 2404          
 2405          BaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue )
 2406          {
 2407   1          BaseType_t xReturn;
 2408   1          Queue_t * const pxQueue = xQueue;
 2409   1      
 2410   1          configASSERT( pxQueue );
 2411   1      
 2412   1          if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0 )
 2413   1          {
 2414   2              xReturn = pdTRUE;
 2415   2          }
 2416   1          else
 2417   1          {
 2418   2              xReturn = pdFALSE;
 2419   2          }
 2420   1      
 2421   1          return xReturn;
 2422   1      } /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
 2423          /*-----------------------------------------------------------*/
 2424          
 2425          static BaseType_t prvIsQueueFull( const Queue_t * pxQueue )
 2426          {
 2427   1          BaseType_t xReturn;
 2428   1      
 2429   1          taskENTER_CRITICAL();
 2430   1          {
 2431   2              if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
 2432   2              {
 2433   3                  xReturn = pdTRUE;
 2434   3              }
 2435   2              else
 2436   2              {
 2437   3                  xReturn = pdFALSE;
 2438   3              }
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 39  

 2439   2          }
 2440   1          taskEXIT_CRITICAL();
 2441   1      
 2442   1          return xReturn;
 2443   1      }
 2444          /*-----------------------------------------------------------*/
 2445          
 2446          BaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue )
 2447          {
 2448   1          BaseType_t xReturn;
 2449   1          Queue_t * const pxQueue = xQueue;
 2450   1      
 2451   1          configASSERT( pxQueue );
 2452   1      
 2453   1          if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
 2454   1          {
 2455   2              xReturn = pdTRUE;
 2456   2          }
 2457   1          else
 2458   1          {
 2459   2              xReturn = pdFALSE;
 2460   2          }
 2461   1      
 2462   1          return xReturn;
 2463   1      } /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
 2464          /*-----------------------------------------------------------*/
 2465          
 2466          #if ( configUSE_CO_ROUTINES == 1 )
               
                   BaseType_t xQueueCRSend( QueueHandle_t xQueue,
                                            const void * pvItemToQueue,
                                            TickType_t xTicksToWait )
                   {
                       BaseType_t xReturn;
                       Queue_t * const pxQueue = xQueue;
               
                       /* If the queue is already full we may have to block.  A critical section
                        * is required to prevent an interrupt removing something from the queue
                        * between the check to see if the queue is full and blocking on the queue. */
                       portDISABLE_INTERRUPTS();
                       {
                           if( prvIsQueueFull( pxQueue ) != pdFALSE )
                           {
                               /* The queue is full - do we want to block or just leave without
                                * posting? */
                               if( xTicksToWait > ( TickType_t ) 0 )
                               {
                                   /* As this is called from a coroutine we cannot block directly, but
                                    * return indicating that we need to block. */
                                   vCoRoutineAddToDelayedList( xTicksToWait, &( pxQueue->xTasksWaitingToSend ) );
                                   portENABLE_INTERRUPTS();
                                   return errQUEUE_BLOCKED;
                               }
                               else
                               {
                                   portENABLE_INTERRUPTS();
                                   return errQUEUE_FULL;
                               }
                           }
                       }
                       portENABLE_INTERRUPTS();
               
                       portDISABLE_INTERRUPTS();
                       {
                           if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
                           {
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 40  

                               /* There is room in the queue, copy the data into the queue. */
                               prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
                               xReturn = pdPASS;
               
                               /* Were any co-routines waiting for data to become available? */
                               if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
                               {
                                   /* In this instance the co-routine could be placed directly
                                    * into the ready list as we are within a critical section.
                                    * Instead the same pending ready list mechanism is used as if
                                    * the event were caused from within an interrupt. */
                                   if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE 
             -)
                                   {
                                       /* The co-routine waiting has a higher priority so record
                                        * that a yield might be appropriate. */
                                       xReturn = errQUEUE_YIELD;
                                   }
                                   else
                                   {
                                       mtCOVERAGE_TEST_MARKER();
                                   }
                               }
                               else
                               {
                                   mtCOVERAGE_TEST_MARKER();
                               }
                           }
                           else
                           {
                               xReturn = errQUEUE_FULL;
                           }
                       }
                       portENABLE_INTERRUPTS();
               
                       return xReturn;
                   }
               
               #endif /* configUSE_CO_ROUTINES */
 2543          /*-----------------------------------------------------------*/
 2544          
 2545          #if ( configUSE_CO_ROUTINES == 1 )
               
                   BaseType_t xQueueCRReceive( QueueHandle_t xQueue,
                                               void * pvBuffer,
                                               TickType_t xTicksToWait )
                   {
                       BaseType_t xReturn;
                       Queue_t * const pxQueue = xQueue;
               
                       /* If the queue is already empty we may have to block.  A critical section
                        * is required to prevent an interrupt adding something to the queue
                        * between the check to see if the queue is empty and blocking on the queue. */
                       portDISABLE_INTERRUPTS();
                       {
                           if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0 )
                           {
                               /* There are no messages in the queue, do we want to block or just
                                * leave with nothing? */
                               if( xTicksToWait > ( TickType_t ) 0 )
                               {
                                   /* As this is a co-routine we cannot block directly, but return
                                    * indicating that we need to block. */
                                   vCoRoutineAddToDelayedList( xTicksToWait, &( pxQueue->xTasksWaitingToReceive ) );
                                   portENABLE_INTERRUPTS();
                                   return errQUEUE_BLOCKED;
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 41  

                               }
                               else
                               {
                                   portENABLE_INTERRUPTS();
                                   return errQUEUE_FULL;
                               }
                           }
                           else
                           {
                               mtCOVERAGE_TEST_MARKER();
                           }
                       }
                       portENABLE_INTERRUPTS();
               
                       portDISABLE_INTERRUPTS();
                       {
                           if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
                           {
                               /* Data is available from the queue. */
                               pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize;
               
                               if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail )
                               {
                                   pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;
                               }
                               else
                               {
                                   mtCOVERAGE_TEST_MARKER();
                               }
               
                               --( pxQueue->uxMessagesWaiting );
                               ( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned
             - ) pxQueue->uxItemSize );
               
                               xReturn = pdPASS;
               
                               /* Were any co-routines waiting for space to become available? */
                               if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
                               {
                                   /* In this instance the co-routine could be placed directly
                                    * into the ready list as we are within a critical section.
                                    * Instead the same pending ready list mechanism is used as if
                                    * the event were caused from within an interrupt. */
                                   if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
                                   {
                                       xReturn = errQUEUE_YIELD;
                                   }
                                   else
                                   {
                                       mtCOVERAGE_TEST_MARKER();
                                   }
                               }
                               else
                               {
                                   mtCOVERAGE_TEST_MARKER();
                               }
                           }
                           else
                           {
                               xReturn = pdFAIL;
                           }
                       }
                       portENABLE_INTERRUPTS();
               
                       return xReturn;
                   }
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 42  

               
               #endif /* configUSE_CO_ROUTINES */
 2637          /*-----------------------------------------------------------*/
 2638          
 2639          #if ( configUSE_CO_ROUTINES == 1 )
               
                   BaseType_t xQueueCRSendFromISR( QueueHandle_t xQueue,
                                                   const void * pvItemToQueue,
                                                   BaseType_t xCoRoutinePreviouslyWoken )
                   {
                       Queue_t * const pxQueue = xQueue;
               
                       /* Cannot block within an ISR so if there is no space on the queue then
                        * exit without doing anything. */
                       if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
                       {
                           prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
               
                           /* We only want to wake one co-routine per ISR, so check that a
                            * co-routine has not already been woken. */
                           if( xCoRoutinePreviouslyWoken == pdFALSE )
                           {
                               if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
                               {
                                   if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE 
             -)
                                   {
                                       return pdTRUE;
                                   }
                                   else
                                   {
                                       mtCOVERAGE_TEST_MARKER();
                                   }
                               }
                               else
                               {
                                   mtCOVERAGE_TEST_MARKER();
                               }
                           }
                           else
                           {
                               mtCOVERAGE_TEST_MARKER();
                           }
                       }
                       else
                       {
                           mtCOVERAGE_TEST_MARKER();
                       }
               
                       return xCoRoutinePreviouslyWoken;
                   }
               
               #endif /* configUSE_CO_ROUTINES */
 2687          /*-----------------------------------------------------------*/
 2688          
 2689          #if ( configUSE_CO_ROUTINES == 1 )
               
                   BaseType_t xQueueCRReceiveFromISR( QueueHandle_t xQueue,
                                                      void * pvBuffer,
                                                      BaseType_t * pxCoRoutineWoken )
                   {
                       BaseType_t xReturn;
                       Queue_t * const pxQueue = xQueue;
               
                       /* We cannot block from an ISR, so check there is data available. If
                        * not then just leave without doing anything. */
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 43  

                       if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
                       {
                           /* Copy the data from the queue. */
                           pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize;
               
                           if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail )
                           {
                               pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;
                           }
                           else
                           {
                               mtCOVERAGE_TEST_MARKER();
                           }
               
                           --( pxQueue->uxMessagesWaiting );
                           ( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned ) p
             -xQueue->uxItemSize );
               
                           if( ( *pxCoRoutineWoken ) == pdFALSE )
                           {
                               if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
                               {
                                   if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
                                   {
                                       *pxCoRoutineWoken = pdTRUE;
                                   }
                                   else
                                   {
                                       mtCOVERAGE_TEST_MARKER();
                                   }
                               }
                               else
                               {
                                   mtCOVERAGE_TEST_MARKER();
                               }
                           }
                           else
                           {
                               mtCOVERAGE_TEST_MARKER();
                           }
               
                           xReturn = pdPASS;
                       }
                       else
                       {
                           xReturn = pdFAIL;
                       }
               
                       return xReturn;
                   }
               
               #endif /* configUSE_CO_ROUTINES */
 2751          /*-----------------------------------------------------------*/
 2752          
 2753          #if ( configQUEUE_REGISTRY_SIZE > 0 )
               
                   void vQueueAddToRegistry( QueueHandle_t xQueue,
                                             const char * pcQueueName ) /*lint !e971 Unqualified char types are allowed 
             -for strings and single characters only. */
                   {
                       UBaseType_t ux;
               
                       configASSERT( xQueue );
               
                       QueueRegistryItem_t * pxEntryToWrite = NULL;
               
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 44  

                       if( pcQueueName != NULL )
                       {
                           /* See if there is an empty space in the registry.  A NULL name denotes
                            * a free slot. */
                           for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
                           {
                               /* Replace an existing entry if the queue is already in the registry. */
                               if( xQueue == xQueueRegistry[ ux ].xHandle )
                               {
                                   pxEntryToWrite = &( xQueueRegistry[ ux ] );
                                   break;
                               }
                               /* Otherwise, store in the next empty location */
                               else if( ( pxEntryToWrite == NULL ) && ( xQueueRegistry[ ux ].pcQueueName == NULL ) )
                               {
                                   pxEntryToWrite = &( xQueueRegistry[ ux ] );
                               }
                               else
                               {
                                   mtCOVERAGE_TEST_MARKER();
                               }
                           }
                       }
               
                       if( pxEntryToWrite != NULL )
                       {
                           /* Store the information on this queue. */
                           pxEntryToWrite->pcQueueName = pcQueueName;
                           pxEntryToWrite->xHandle = xQueue;
               
                           traceQUEUE_REGISTRY_ADD( xQueue, pcQueueName );
                       }
                   }
               
               #endif /* configQUEUE_REGISTRY_SIZE */
 2799          /*-----------------------------------------------------------*/
 2800          
 2801          #if ( configQUEUE_REGISTRY_SIZE > 0 )
               
                   const char * pcQueueGetName( QueueHandle_t xQueue ) /*lint !e971 Unqualified char types are allowed f
             -or strings and single characters only. */
                   {
                       UBaseType_t ux;
                       const char * pcReturn = NULL; /*lint !e971 Unqualified char types are allowed for strings and sin
             -gle characters only. */
               
                       configASSERT( xQueue );
               
                       /* Note there is nothing here to protect against another task adding or
                        * removing entries from the registry while it is being searched. */
               
                       for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
                       {
                           if( xQueueRegistry[ ux ].xHandle == xQueue )
                           {
                               pcReturn = xQueueRegistry[ ux ].pcQueueName;
                               break;
                           }
                           else
                           {
                               mtCOVERAGE_TEST_MARKER();
                           }
                       }
               
                       return pcReturn;
                   } /*lint !e818 xQueue cannot be a pointer to const because it is a typedef. */
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 45  

               
               #endif /* configQUEUE_REGISTRY_SIZE */
 2830          /*-----------------------------------------------------------*/
 2831          
 2832          #if ( configQUEUE_REGISTRY_SIZE > 0 )
               
                   void vQueueUnregisterQueue( QueueHandle_t xQueue )
                   {
                       UBaseType_t ux;
               
                       configASSERT( xQueue );
               
                       /* See if the handle of the queue being unregistered in actually in the
                        * registry. */
                       for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
                       {
                           if( xQueueRegistry[ ux ].xHandle == xQueue )
                           {
                               /* Set the name to NULL to show that this slot if free again. */
                               xQueueRegistry[ ux ].pcQueueName = NULL;
               
                               /* Set the handle to NULL to ensure the same queue handle cannot
                                * appear in the registry twice if it is added, removed, then
                                * added again. */
                               xQueueRegistry[ ux ].xHandle = ( QueueHandle_t ) 0;
                               break;
                           }
                           else
                           {
                               mtCOVERAGE_TEST_MARKER();
                           }
                       }
                   } /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
               
               #endif /* configQUEUE_REGISTRY_SIZE */
 2863          /*-----------------------------------------------------------*/
 2864          
 2865          #if ( configUSE_TIMERS == 1 )
               
                   void vQueueWaitForMessageRestricted( QueueHandle_t xQueue,
                                                        TickType_t xTicksToWait,
                                                        const BaseType_t xWaitIndefinitely )
                   {
                       Queue_t * const pxQueue = xQueue;
               
                       /* This function should not be called by application code hence the
                        * 'Restricted' in its name.  It is not part of the public API.  It is
                        * designed for use by kernel code, and has special calling requirements.
                        * It can result in vListInsert() being called on a list that can only
                        * possibly ever have one item in it, so the list will be fast, but even
                        * so it should be called with the scheduler locked and not from a critical
                        * section. */
               
                       /* Only do anything if there are no messages in the queue.  This function
                        *  will not actually cause the task to block, just place it on a blocked
                        *  list.  It will not block until the scheduler is unlocked - at which
                        *  time a yield will be performed.  If an item is added to the queue while
                        *  the queue is locked, and the calling task blocks on the queue, then the
                        *  calling task will be immediately unblocked when the queue is unlocked. */
                       prvLockQueue( pxQueue );
               
                       if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0U )
                       {
                           /* There is nothing in the queue, block for the specified period. */
                           vTaskPlaceOnEventListRestricted( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait, xWaitInd
             -efinitely );
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 46  

                       }
                       else
                       {
                           mtCOVERAGE_TEST_MARKER();
                       }
               
                       prvUnlockQueue( pxQueue );
                   }
               
               #endif /* configUSE_TIMERS */
 2903          /*-----------------------------------------------------------*/
 2904          
 2905          #if ( ( configUSE_QUEUE_SETS == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
               
                   QueueSetHandle_t xQueueCreateSet( const UBaseType_t uxEventQueueLength )
                   {
                       QueueSetHandle_t pxQueue;
               
                       pxQueue = xQueueGenericCreate( uxEventQueueLength, ( UBaseType_t ) sizeof( Queue_t * ), queueQUEU
             -E_TYPE_SET );
               
                       return pxQueue;
                   }
               
               #endif /* configUSE_QUEUE_SETS */
 2917          /*-----------------------------------------------------------*/
 2918          
 2919          #if ( configUSE_QUEUE_SETS == 1 )
               
                   BaseType_t xQueueAddToSet( QueueSetMemberHandle_t xQueueOrSemaphore,
                                              QueueSetHandle_t xQueueSet )
                   {
                       BaseType_t xReturn;
               
                       taskENTER_CRITICAL();
                       {
                           if( ( ( Queue_t * ) xQueueOrSemaphore )->pxQueueSetContainer != NULL )
                           {
                               /* Cannot add a queue/semaphore to more than one queue set. */
                               xReturn = pdFAIL;
                           }
                           else if( ( ( Queue_t * ) xQueueOrSemaphore )->uxMessagesWaiting != ( UBaseType_t ) 0 )
                           {
                               /* Cannot add a queue/semaphore to a queue set if there are already
                                * items in the queue/semaphore. */
                               xReturn = pdFAIL;
                           }
                           else
                           {
                               ( ( Queue_t * ) xQueueOrSemaphore )->pxQueueSetContainer = xQueueSet;
                               xReturn = pdPASS;
                           }
                       }
                       taskEXIT_CRITICAL();
               
                       return xReturn;
                   }
               
               #endif /* configUSE_QUEUE_SETS */
 2951          /*-----------------------------------------------------------*/
 2952          
 2953          #if ( configUSE_QUEUE_SETS == 1 )
               
                   BaseType_t xQueueRemoveFromSet( QueueSetMemberHandle_t xQueueOrSemaphore,
                                                   QueueSetHandle_t xQueueSet )
                   {
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 47  

                       BaseType_t xReturn;
                       Queue_t * const pxQueueOrSemaphore = ( Queue_t * ) xQueueOrSemaphore;
               
                       if( pxQueueOrSemaphore->pxQueueSetContainer != xQueueSet )
                       {
                           /* The queue was not a member of the set. */
                           xReturn = pdFAIL;
                       }
                       else if( pxQueueOrSemaphore->uxMessagesWaiting != ( UBaseType_t ) 0 )
                       {
                           /* It is dangerous to remove a queue from a set when the queue is
                            * not empty because the queue set will still hold pending events for
                            * the queue. */
                           xReturn = pdFAIL;
                       }
                       else
                       {
                           taskENTER_CRITICAL();
                           {
                               /* The queue is no longer contained in the set. */
                               pxQueueOrSemaphore->pxQueueSetContainer = NULL;
                           }
                           taskEXIT_CRITICAL();
                           xReturn = pdPASS;
                       }
               
                       return xReturn;
                   } /*lint !e818 xQueueSet could not be declared as pointing to const as it is a typedef. */
               
               #endif /* configUSE_QUEUE_SETS */
 2988          /*-----------------------------------------------------------*/
 2989          
 2990          #if ( configUSE_QUEUE_SETS == 1 )
               
                   QueueSetMemberHandle_t xQueueSelectFromSet( QueueSetHandle_t xQueueSet,
                                                               TickType_t const xTicksToWait )
                   {
                       QueueSetMemberHandle_t xReturn = NULL;
               
                       ( void ) xQueueReceive( ( QueueHandle_t ) xQueueSet, &xReturn, xTicksToWait ); /*lint !e961 Casti
             -ng from one typedef to another is not redundant. */
                       return xReturn;
                   }
               
               #endif /* configUSE_QUEUE_SETS */
 3002          /*-----------------------------------------------------------*/
 3003          
 3004          #if ( configUSE_QUEUE_SETS == 1 )
               
                   QueueSetMemberHandle_t xQueueSelectFromSetFromISR( QueueSetHandle_t xQueueSet )
                   {
                       QueueSetMemberHandle_t xReturn = NULL;
               
                       ( void ) xQueueReceiveFromISR( ( QueueHandle_t ) xQueueSet, &xReturn, NULL ); /*lint !e961 Castin
             -g from one typedef to another is not redundant. */
                       return xReturn;
                   }
               
               #endif /* configUSE_QUEUE_SETS */
 3015          /*-----------------------------------------------------------*/
 3016          
 3017          #if ( configUSE_QUEUE_SETS == 1 )
               
                   static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue )
                   {
                       Queue_t * pxQueueSetContainer = pxQueue->pxQueueSetContainer;
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 48  

                       BaseType_t xReturn = pdFALSE;
               
                       /* This function must be called form a critical section. */
               
                       /* The following line is not reachable in unit tests because every call
                        * to prvNotifyQueueSetContainer is preceded by a check that
                        * pxQueueSetContainer != NULL */
                       configASSERT( pxQueueSetContainer ); /* LCOV_EXCL_BR_LINE */
                       configASSERT( pxQueueSetContainer->uxMessagesWaiting < pxQueueSetContainer->uxLength );
               
                       if( pxQueueSetContainer->uxMessagesWaiting < pxQueueSetContainer->uxLength )
                       {
                           const int8_t cTxLock = pxQueueSetContainer->cTxLock;
               
                           traceQUEUE_SET_SEND( pxQueueSetContainer );
               
                           /* The data copied is the handle of the queue that contains data. */
                           xReturn = prvCopyDataToQueue( pxQueueSetContainer, &pxQueue, queueSEND_TO_BACK );
               
                           if( cTxLock == queueUNLOCKED )
                           {
                               if( listLIST_IS_EMPTY( &( pxQueueSetContainer->xTasksWaitingToReceive ) ) == pdFALSE )
                               {
                                   if( xTaskRemoveFromEventList( &( pxQueueSetContainer->xTasksWaitingToReceive ) ) != p
             -dFALSE )
                                   {
                                       /* The task waiting has a higher priority. */
                                       xReturn = pdTRUE;
                                   }
                                   else
                                   {
                                       mtCOVERAGE_TEST_MARKER();
                                   }
                               }
                               else
                               {
                                   mtCOVERAGE_TEST_MARKER();
                               }
                           }
                           else
                           {
                               configASSERT( cTxLock != queueINT8_MAX );
               
                               pxQueueSetContainer->cTxLock = ( int8_t ) ( cTxLock + 1 );
                           }
                       }
                       else
                       {
                           mtCOVERAGE_TEST_MARKER();
                       }
               
                       return xReturn;
                   }
               
               #endif /* configUSE_QUEUE_SETS */


Module Information          Static   Overlayable
------------------------------------------------
  code size            =    ------     ------
  ecode size           =      3503     ------
  data size            =    ------     ------
  idata size           =    ------     ------
  pdata size           =    ------     ------
  xdata size           =    ------     ------
  xdata-const size     =    ------     ------
  edata size           =    ------     ------
C251 COMPILER V5.60.0,  queue                                                              21/09/22  22:20:49  PAGE 49  

  bit size             =    ------     ------
  ebit size            =    ------     ------
  bitaddressable size  =    ------     ------
  ebitaddressable size =    ------     ------
  far data size        =    ------     ------
  huge data size       =    ------     ------
  const size           =    ------     ------
  hconst size          =    ------     ------
End of Module Information.


C251 COMPILATION COMPLETE.  0 WARNING(S),  0 ERROR(S)
